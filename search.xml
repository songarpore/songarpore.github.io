<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[pipenv--基于项目的虚拟环境管理]]></title>
    <url>%2Fpython%2Fpipenv.html</url>
    <content type="text"><![CDATA[pipenv相当于pip+virtualenv,可是使得我们更加关注于项目的管理；其优势是不需要再分别使用pip和virtualenv，只需直接使用pipenv即可，pipenv会自动帮你创建虚拟环境，以及安装三方库，也会自动的记录你项目依赖的所有三方库，其使用pipfile和pipifile.lock取代了requiredments.txt 安装：1$ pip install pipenv 常用命令pipenv 具有的选项：123456789101112131415161718$ pipenvUsage: pipenv [OPTIONS] COMMAND [ARGS]...Options: --where 显示项目文件所在路径 --venv 显示虚拟环境实际文件所在路径 --py 显示虚拟环境Python解释器所在路径 --envs 显示虚拟环境的选项变量 --rm 删除虚拟环境 --bare 最小化输出 --completion 完整输出 --man 显示帮助页面 --three / --two 使用Python 3/2创建虚拟环境（注意本机已安装的Python版本） --python TEXT 指定某个Python版本作为虚拟环境的安装源 --site-packages 附带安装原Python解释器中的第三方库 --jumbotron An easter egg, effectively. --version 版本信息 -h, --help 帮助信息 pipenv 可使用的命令参数：12345678910Commands: check 检查安全漏洞 graph 显示当前依赖关系图信息 install 安装虚拟环境或者第三方库 lock 锁定并生成Pipfile.lock文件 open 在编辑器中查看一个库 run 在虚拟环境中运行命令 shell 进入虚拟环境 uninstall 卸载一个库 update 卸载当前所有的包，并安装它们的最新版本 一些例子：Usage Examples:1234567891011121314151617181920Create a new project using Python 3.6, specifically:$ pipenv --python 3.6Install all dependencies for a project (including dev):$ pipenv install --devCreate a lockfile containing pre-releases:$ pipenv lock --preShow a graph of your installed dependencies:$ pipenv graphCheck your installed dependencies for security vulnerabilities:$ pipenv checkInstall a local setup.py into your virtual environment/Pipfile:$ pipenv install -e .Use a lower-level pip command:$ pipenv run pip freeze 使用具体使用步骤如下： 第一步：创建虚拟环境。命令：12$ cd myproject$ pipenv install --three 查看相关信息： 项目位置： pipenv --where 虚拟环境位置： pipenv --venv 解释器位置： pipenv --py 第二步，激活虚拟环境。命令：1pipenv shell 第三步：该干啥干啥下面举几个例子。3.1执行代码 ：python3 xxx.py //使用虚拟环境 3.2 安装包：pipenv install [name] 3.3查看包的依赖结构 ：pipenv graph 3.4卸载包 ：pipenv uninstall 包名 第四步：推出虚拟环境命令：exit 或者 ctrl+d 或者直接关闭shell 窗口 第五步：删除虚拟环境命令：1pipenv --rm]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pipenv</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[udsoncan.Request源码]]></title>
    <url>%2Fuds%2Fudsoncan.Request.html</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129from udsoncan import servicesimport inspectimport structclass Request: """ Represents a UDS Request. :param service: The service for which to make the request. This parameter must be a class that extends :class:`udsoncan.services.BaseService` :type service: class :param subfunction: The service subfunction. This value may be ignored if the given service does not supports subfunctions :type subfunction: int or None :param suppress_positive_response: Indicates that the server should not send a response if the response code is positive. This parameter has effect only when the given service supports subfunctions :type suppress_positive_response: bool :param data: The service data appended after service ID and payload :type data: bytes """ def __init__(self, service = None, subfunction = None, suppress_positive_response = False, data=None): if service is None: self.service = None elif isinstance(service, services.BaseService): self.service = service.__class__ elif inspect.isclass(service) and issubclass(service, services.BaseService): self.service = service elif service is not None: raise ValueError("Given service must be a service class or instance") if not isinstance(suppress_positive_response, bool): raise ValueError("suppress_positive_response must be a boolean value") if subfunction is not None: if isinstance(subfunction, int): self.subfunction = subfunction else: raise ValueError("Given subfunction must be a valid integer") else: self.subfunction = None if self.service is not None: if suppress_positive_response and self.service.use_subfunction() == False: raise ValueError('Cannot suppress positive response for service %s. This service does not have a subfunction' % (self.service.get_name())) self.suppress_positive_response = suppress_positive_response if data is not None and not isinstance(data, bytes): raise ValueError("data must be a valid bytes object") self.data = data def get_payload(self, suppress_positive_response=None): """ Generates a payload to be given to the underlying protocol. This method is meant to be used by a UDS client :return: A payload to be sent through the underlying protocol :rtype: bytes """ if not issubclass(self.service, services.BaseService): raise ValueError("Cannot generate a payload. Given service is not a subclass of BaseService") if self.service.use_subfunction() and not isinstance(self.subfunction, int): raise ValueError("Cannot generate a payload. Given subfunction is not a valid integer") requestid = self.service.request_id() # Returns the service ID used to make a client request payload = struct.pack("B", requestid) if self.service.use_subfunction(): subfunction = self.subfunction if suppress_positive_response is None: if self.suppress_positive_response: subfunction |= 0x80 else: if suppress_positive_response == True: subfunction |= 0x80 elif suppress_positive_response == False: subfunction &amp;= ~0x80 payload += struct.pack("B", subfunction) else: if suppress_positive_response == True or self.suppress_positive_response == True: raise ValueError('Cannot suppress positive response for service %s. This service does not have a subfunction' % (self.service.get_name())) if self.data is not None: payload += self.data return payload @classmethod def from_payload(cls, payload): """ Creates a ``Request`` object from a payload coming from the underlying protocols. This method is meant to be used by a UDS server :param payload: The payload of data to parse :type payload: bytes :return: A :ref:`Request&lt;Request&gt;` object with populated fields :rtype: :ref:`Request&lt;Request&gt;` """ req = cls() if len(payload) &gt;= 1: req.service = services.cls_from_request_id(payload[0]) if req.service is not None: # Invalid service ID will make service None offset = 0 if req.service.use_subfunction(): offset += 1 if len(payload) &gt;= offset+1: req.subfunction = int(payload[1]) &amp; 0x7F req.suppress_positive_response = True if payload[1] &amp; 0x80 &gt; 0 else False if len(payload) &gt; offset+1: req.data = payload[offset+1:] return req def __repr__(self): suppress_positive_response = '[SuppressPosResponse] ' if self.suppress_positive_response else '' subfunction_name = '(subfunction=%d) ' % self.subfunction if self.service.use_subfunction() and self.subfunction is not None else '' bytesize = len(self.data) if self.data is not None else 0 return '&lt;Request: [%s] %s- %d data bytes %sat 0x%08x&gt;' % (self.service.get_name(), subfunction_name, bytesize, suppress_positive_response, id(self)) def __len__(self): try: return len(self.get_payload()) except: return 0]]></content>
      <categories>
        <category>uds</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>udsoncan</tag>
        <tag>uds</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[udsoncan.Response源码]]></title>
    <url>%2Fuds%2Fudsoncan.Response.html</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294import inspectimport structclass Response: """ Represents a server Response to a client Request :param service: The service implied by this response. :type service: class :param code: The response code :type code: int :param data: The response data encoded after the service and response code :type data: bytes .. data:: valid (boolean) True if the response content is valid. Only ``invalid_reason`` is guaranteed to have a meaningful value if this value is False .. data:: invalid_reason (string) String explaining why the response is invalid. .. data:: service (class) The response target :ref:`service&lt;Services&gt;` class .. data:: positive (boolean) True if the response code is 0 (PositiveResponse), False otherwise .. data:: code (int) The response code. .. data:: code_name (string) The response code name. .. data:: data (bytes) The response data. All the payload content, except the service number and the response code .. data:: service_data (object) The content of ``data`` interpreted by a service; can be any type of content. .. data:: original_payload (bytes) When the response is built with `Response.from_payload`, this property contains a copy of the payload used. None otherwise. .. data:: unexpected (boolean) Indicates that the response was unexpected. Set by an external source such as the :ref:`Client&lt;Client&gt;` object """ class Code: PositiveResponse = 0 GeneralReject = 0x10 ServiceNotSupported = 0x11 SubFunctionNotSupported = 0x12 IncorrectMessageLegthOrInvalidFormat = 0x13 ResponseTooLong = 0x14 BusyRepeatRequest = 0x21 ConditionsNotCorrect = 0x22 RequestSequenceError = 0x24 NoResponseFromSubnetComponent = 0x25 FailurePreventsExecutionOfRequestedAction = 0x26 RequestOutOfRange = 0x31 SecurityAccessDenied = 0x33 InvalidKey = 0x35 ExceedNumberOfAttempts = 0x36 RequiredTimeDelayNotExpired = 0x37 UploadDownloadNotAccepted = 0x70 TransferDataSuspended = 0x71 GeneralProgrammingFailure = 0x72 WrongBlockSequenceCounter = 0x73 RequestCorrectlyReceived_ResponsePending = 0x78 SubFunctionNotSupportedInActiveSession = 0x7E ServiceNotSupportedInActiveSession = 0x7F RpmTooHigh = 0x81 RpmTooLow = 0x82 EngineIsRunning = 0x83 EngineIsNotRunning = 0x84 EngineRunTimeTooLow = 0x85 TemperatureTooHigh = 0x86 TemperatureTooLow = 0x87 VehicleSpeedTooHigh = 0x88 VehicleSpeedTooLow = 0x89 ThrottlePedalTooHigh = 0x8A ThrottlePedalTooLow = 0x8B TransmissionRangeNotInNeutral = 0x8C TransmissionRangeNotInGear = 0x8D ISOSAEReserved = 0x8E BrakeSwitchNotClosed = 0x8F ShifterLeverNotInPark = 0x90 TorqueConverterClutchLocked = 0x91 VoltageTooHigh = 0x92 VoltageTooLow = 0x93 #Defined by ISO-15764. Offset of 0x38 is defined within UDS standard (ISO-14229) GeneralSecurityViolation = 0x38 + 0 SecuredModeRequested = 0x38 + 1 InsufficientProtection = 0x38 + 2 TerminationWithSignatureRequested = 0x38 + 3 AccessDenied = 0x38 + 4 VersionNotSupported = 0x38 + 5 SecuredLinkNotSupported = 0x38 + 6 CertificateNotAvailable = 0x38 + 7 AuditTrailInformationNotAvailable = 0x38 + 8 #Returns the name of the response code as a string @classmethod def get_name(cls, given_id): if given_id is None: return "" for member in inspect.getmembers(cls): if isinstance(member[1], int): if member[1] == given_id: return member[0] return str(given_id) #Tells if a code is a negative code @classmethod def is_negative(cls, given_id): if given_id in [None, cls.PositiveResponse]: return False for member in inspect.getmembers(cls): if isinstance(member[1], int): if member[1] == given_id: return True return False def __init__(self, service = None, code = None, data=None): from udsoncan import services if service is None: self.service = None elif isinstance(service, services.BaseService): self.service = service.__class__ elif inspect.isclass(service) and issubclass(service, services.BaseService): self.service = service elif service is not None: raise ValueError("Given service must be a service class or instance") self.positive = False self.code = None self.code_name = "" self.valid = False self.invalid_reason = "Object not initialized" self.service_data = None self.original_payload = None self.unexpected = False self.service = service if data is not None: if not isinstance(data, bytes): raise ValueError("Given data must be a valid bytes object") self.data = data if data is not None else b'' if code is not None: if not isinstance(code, int): raise ValueError("Response code must be a valid integer") elif code &lt; 0 or code &gt; 0xFF: raise ValueError("Response code must be an integer between 0 and 0xFF") self.code=code self.code_name = Response.Code.get_name(code) if not Response.Code.is_negative(code): self.positive=True if self.service is not None and self.code is not None: self.valid = True self.invalid_reason = "" #Used by server def get_payload(self): """ Generates a payload to be given to the underlying protocol. This method is meant to be used by a UDS server :return: A payload to be sent through the underlying protocol :rtype: bytes """ from udsoncan import services if not isinstance(self.service, services.BaseService) and not issubclass(self.service, services.BaseService): raise ValueError("Cannot make payload from response object. Given service is not a valid service object") if not isinstance(self.code, int): raise ValueError("Cannot make payload from response object. Given response code is not a valid integer") payload = b'' if self.positive: payload += struct.pack("B", self.service.response_id()) else: payload += b'\x7F' payload += struct.pack("B", self.service.request_id()) payload += struct.pack('B', self.code) if self.data is not None and self.service.has_response_data(): payload += self.data return payload # Analyzes a TP frame and builds a Response object. Used by client @classmethod def from_payload(cls, payload): """ Creates a ``Response`` object from a payload coming from the underlying protocol. This method is meant to be used by a UDS client :param payload: The payload of data to parse :type payload: bytes :return: A :ref:`Response&lt;Response&gt;` object with populated fields :rtype: :ref:`Response&lt;Response&gt;` """ from udsoncan import services response = cls() response.original_payload = payload # may be useful for debugging if len(payload) &lt; 1: response.valid = False response.invalid_reason = "Payload is empty" return response if payload[0] != 0x7F: # Positive response.service = services.cls_from_response_id(payload[0]) if response.service is None: response.valid = False response.invalid_reason = "Payload first byte is not a know service response ID." return response data_start=1 response.positive = True if len(payload) &lt; 2 and response.service.has_response_data() : response.valid = False response.positive = False response.invalid_reason = "Payload must be at least 2 bytes long (service and response)" return response response.code = Response.Code.PositiveResponse response.code_name = Response.Code.get_name(Response.Code.PositiveResponse) else: # Negative response response.positive = False data_start=3 if len(payload) &lt; 2 : response.valid = False response.invalid_reason= "Incomplete invalid response service (7Fxx)" return response response.service = services.cls_from_request_id(payload[1]) #Request id, not response id if response.service is None: response.valid = False response.invalid_reason = "Payload second byte is not a known service request ID." return response if len(payload) &lt; 3: response.valid=False response.invalid_reason= "Response code missing" return response response.code = int(payload[2]) response.code_name = Response.Code.get_name(response.code) response.valid = True response.invalid_reason = "" if len(payload) &gt; data_start: response.data = payload[data_start:] return response def __repr__(self): responsename = Response.Code.get_name(Response.Code.PositiveResponse) if self.positive else 'NegativeResponse(%s)' % self.code_name bytesize = len(self.data) if self.data is not None else 0 return '&lt;%s: [%s] - %d data bytes at 0x%08x&gt;' % (responsename, self.service.get_name(), bytesize, id(self)) def __len__(self): try: return len(self.get_payload()) except: return 0]]></content>
      <categories>
        <category>uds</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>udsoncan</tag>
        <tag>uds</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[请求与应答]]></title>
    <url>%2Fuds%2FRequest%20and%20Response.html</url>
    <content type="text"><![CDATA[client和server交换的消息由Request和Response表示。 client向server发送的请求包含service number(SID)，可选子subfunction和一些data。server处理Request并作出Response，该应答包含SID，响应代码和一些其他数据。 以下类提供了操作UDS Request和Response所必需的接口。 Request12345req = Request(service=ECUReset, subfunction=1, data=b'\x99\x88')payload = req.get_payload()print(payload) # b'\x11\x01\x99\x88'req2 = Request.from_payload(payload)print(req2) # &lt;Request: [ECUReset] (subfunction=1) - 2 data bytes at 0x12345678&gt; 1234567891011class udsoncan.Request(service=None, subfunction=None, suppress_positive_response=False, data=None)#代表一个UDS Request.Parameters: service (class) – The service for which to make the request. This parameter must be a class that extends udsoncan.services.BaseService subfunction (int or None) – The service subfunction. This value may be ignored if the given service does not supports subfunctions suppress_positive_response (bool) – Indicates that the server should not send a response if the response code is positive. This parameter has effect only when the given service supports subfunctions data (bytes) – The service data appended after service ID and payload 123456Request.get_payload(suppress_positive_response=None)#生成要提供给底层协议的有效负载。 此函数旨在供`UDS client`使用 Returns: A payload to be sent through the underlying protocol Return type: bytes 1234567classmethod Request.from_payload(payload)#根据来自底层协议的payload创建Request对象。 此函数旨在由UDS server使用 Parameters: payload (bytes) – The payload of data to parse Returns: A Request object with populated fields Return type: Request Response12345response = Response(service=ECUReset, code=Response.Code.PositiveResponse, data=b'\x11\x22')payload = response.get_payload()print(payload) # b'\x51\x11\x22'response2 = Response.from_payload(payload)print(response2) # &lt;PositiveResponse: [ECUReset] - 2 data bytes at 0x7f9367e619b0&gt; 1class udsoncan.Response(service=None, code=None, data=None) #表示service对client请求的响应Parameters: service (class) – The service implied by this response. code (int) – The response code data (bytes) – The response data encoded after the service and response code valid (boolean) True if the response content is valid. Only invalid_reason is guaranteed to have a meaningful value if this value is False invalid_reason (string) String explaining why the response is invalid. service (class) The response target service class positive (boolean) True if the response code is 0 (PositiveResponse), False otherwise code (int) The response code. code_name (string) The response code name. data (bytes) The response data. All the payload content, except the service number and the response code service_data (object) The content of data interpreted by a service; can be any type of content. original_payload (bytes) When the response is built with Response.from_payload, this property contains a copy of the payload used. None otherwise. unexpected (boolean) Indicates that the response was unexpected. Set by an external source such as the Client object 12Response.get_payload()#生成要提供给底层协议的有效负载。 此函数旨在供`UDS client`使用 Returns: A payload to be sent through the underlying protocolReturn type: bytes 12classmethod Response.from_payload(payload)#根据来自底层协议的payload创建Response对象。 此函数旨在由UDS client使用 Parameters: payload (bytes) – The payload of data to parse Returns:A Response object with populated fields Return type: Response Response Codes12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Response.Code PositiveResponse = 0 GeneralReject = 16 ServiceNotSupported = 17 SubFunctionNotSupported = 18 IncorrectMessageLegthOrInvalidFormat = 19 ResponseTooLong = 20 BusyRepeatRequest = 33 ConditionsNotCorrect = 34 RequestSequenceError = 36 NoResponseFromSubnetComponent = 37 FailurePreventsExecutionOfRequestedAction = 38 RequestOutOfRange = 49 SecurityAccessDenied = 51 InvalidKey = 53 ExceedNumberOfAttempts = 54 RequiredTimeDelayNotExpired = 55 UploadDownloadNotAccepted = 112 TransferDataSuspended = 113 GeneralProgrammingFailure = 114 WrongBlockSequenceCounter = 115 RequestCorrectlyReceived_ResponsePending = 120 SubFunctionNotSupportedInActiveSession = 126 ServiceNotSupportedInActiveSession = 127 RpmTooHigh = 129 RpmTooLow = 130 EngineIsRunning = 131 EngineIsNotRunning = 132 EngineRunTimeTooLow = 133 TemperatureTooHigh = 134 TemperatureTooLow = 135 VehicleSpeedTooHigh = 136 VehicleSpeedTooLow = 137 ThrottlePedalTooHigh = 138 ThrottlePedalTooLow = 139 TransmissionRangeNotInNeutral = 140 TransmissionRangeNotInGear = 141 ISOSAEReserved = 142 BrakeSwitchNotClosed = 143 ShifterLeverNotInPark = 144 TorqueConverterClutchLocked = 145 VoltageTooHigh = 146 VoltageTooLow = 147 GeneralSecurityViolation = 56 SecuredModeRequested = 57 InsufficientProtection = 58 TerminationWithSignatureRequested = 59 AccessDenied = 60 VersionNotSupported = 61 SecuredLinkNotSupported = 62 CertificateNotAvailable = 63 AuditTrailInformationNotAvailable = 64]]></content>
      <categories>
        <category>uds</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>udsoncan</tag>
        <tag>uds</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[udsoncan.connections源码]]></title>
    <url>%2Fuds%2Fudsoncan.connections.html</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526import socketimport queueimport threadingimport loggingimport binasciiimport sysfrom abc import ABC, abstractmethodimport functoolsimport timetry: import can _import_can_err = Noneexcept Exception as e: _import_can_err = etry: import isotp _import_isotp_err = Noneexcept Exception as e: _import_isotp_err = efrom udsoncan.Request import Requestfrom udsoncan.Response import Responsefrom udsoncan.exceptions import TimeoutExceptionclass BaseConnection(ABC): def __init__(self, name=None): if name is None: self.name = 'Connection' else: self.name = 'Connection[%s]' % (name) self.logger = logging.getLogger(self.name) def send(self, data): """Sends data to the underlying transport protocol :param data: The data or object to send. If a Request or Response is given, the value returned by get_payload() will be sent. :type data: bytes, Request, Response :returns: None """ if isinstance(data, Request) or isinstance(data, Response): payload = data.get_payload() else : payload = data self.logger.debug('Sending %d bytes : [%s]' % (len(payload), binascii.hexlify(payload) )) self.specific_send(payload) def wait_frame(self, timeout=2, exception=False): """Waits for the reception of a frame of data from the underlying transport protocol :param timeout: The maximum amount of time to wait before giving up in seconds :type timeout: int :param exception: Boolean value indicating if this function may return exceptions. When ``True``, all exceptions may be raised, including ``TimeoutException`` When ``False``, all exceptions will be logged as ``DEBUG`` and ``None`` will be returned. :type exception: bool :returns: Received data :rtype: bytes or None """ try: frame = self.specific_wait_frame(timeout=timeout) except Exception as e: self.logger.debug('No data received: [%s] - %s ' % (e.__class__.__name__, str(e))) if exception == True: raise else: frame = None if frame is not None: self.logger.debug('Received %d bytes : [%s]' % (len(frame), binascii.hexlify(frame) )) return frame def __enter__(self): return self @abstractmethod def specific_send(self, payload): """The implementation of the send method. :param payload: Data to send :type payload: bytes :returns: None """ pass @abstractmethod def specific_wait_frame(self, timeout=2): """The implementation of the ``wait_frame`` method. :param timeout: The maximum amount of time to wait before giving up :type timeout: int :returns: Received data :rtype: bytes or None """ pass @abstractmethod def open(self): """ Set up the connection object. :returns: None """ pass @abstractmethod def close(self): """ Close the connection object :returns: None """ pass @abstractmethod def empty_rxqueue(self): """ Empty all unread data in the reception buffer. :returns: None """ pass def __exit__(self, type, value, traceback): passclass SocketConnection(BaseConnection): """ Sends and receives data through a socket. :param sock: The socket to use. This socket must be bound and ready to use. Only ``send()`` and ``recv()`` will be called by this Connection :type sock: socket.socket :param bufsize: Maximum buffer size of the socket, this value is passed to ``recv()`` :type bufsize: int :param name: This name is included in the logger name so that its output can be redirected. The logger name will be ``Connection[&lt;name&gt;]`` :type name: string """ def __init__(self, sock, bufsize=4095, name=None): BaseConnection.__init__(self, name) self.rxqueue = queue.Queue() self.exit_requested = False self.opened = False self.rxthread = None self.sock = sock self.sock.settimeout(0.1) # for recv self.bufsize=bufsize def open(self): self.exit_requested = False self.rxthread = threading.Thread(target=self.rxthread_task) self.rxthread.start() self.opened = True self.logger.info('Connection opened') return self def __enter__(self): return self def __exit__(self, type, value, traceback): self.close() def is_open(self): return self.opened def rxthread_task(self): while not self.exit_requested: try: data = self.sock.recv(self.bufsize) if data is not None: self.rxqueue.put(data) except socket.timeout: pass except Exception: self.exit_requested = True def close(self): self.exit_requested = True self.rxthread.join() self.opened = False self.logger.info('Connection closed') def specific_send(self, payload): self.sock.send(payload) def specific_wait_frame(self, timeout=2): if not self.opened: raise RuntimeError("Connection is not open") timedout = False frame = None try: frame = self.rxqueue.get(block=True, timeout=timeout) except queue.Empty: timedout = True if timedout: raise TimeoutException("Did not received frame in time (timeout=%s sec)" % timeout) return frame def empty_rxqueue(self): while not self.rxqueue.empty(): self.rxqueue.get()class IsoTPSocketConnection(BaseConnection): """ Sends and receives data through an ISO-TP socket. Makes cleaner code than SocketConnection but offers no additional functionality. The `can-isotp module &lt;https://github.com/pylessard/python-can-isotp&gt;`_ must be installed in order to use this connection :param interface: The can interface to use (example: `can0`) :type interface: string :param rxid: The reception CAN id :type rxid: int :param txid: The transmission CAN id :type txid: int :param name: This name is included in the logger name so that its output can be redirected. The logger name will be ``Connection[&lt;name&gt;]`` :type name: string :param tpsock: An optional ISO-TP socket to use instead of creating one. :type tpsock: isotp.socket """ def __init__(self, interface, rxid, txid, name=None, tpsock=None): BaseConnection.__init__(self, name) self.interface=interface self.rxid=rxid self.txid=txid self.rxqueue = queue.Queue() self.exit_requested = False self.opened = False if tpsock is None: if 'isotp' not in sys.modules: if _import_isotp_err is None: raise ImportError('isotp module is not loaded') else: raise _import_isotp_err self.tpsock = isotp.socket(timeout=0.1) else: self.tpsock = tpsock def open(self): self.tpsock.bind(self.interface, rxid=self.rxid, txid=self.txid) self.exit_requested = False self.rxthread = threading.Thread(target=self.rxthread_task) self.rxthread.start() self.opened = True self.logger.info('Connection opened') return self def __enter__(self): return self def __exit__(self, type, value, traceback): self.close() def is_open(self): return self.tpsock.bound def rxthread_task(self): while not self.exit_requested: try: data = self.tpsock.recv() if data is not None: self.rxqueue.put(data) except socket.timeout: pass except Exception: self.exit_requested = True def close(self): self.exit_requested = True self.rxthread.join() self.tpsock.close() self.opened = False self.logger.info('Connection closed') def specific_send(self, payload): self.tpsock.send(payload) def specific_wait_frame(self, timeout=2): if not self.opened: raise RuntimeError("Connection is not open") timedout = False frame = None try: frame = self.rxqueue.get(block=True, timeout=timeout) except queue.Empty: timedout = True if timedout: raise TimeoutException("Did not received ISOTP frame in time (timeout=%s sec)" % timeout) return frame def empty_rxqueue(self): while not self.rxqueue.empty(): self.rxqueue.get()class IsoTPConnection(IsoTPSocketConnection): """ Same as :class:`IsoTPSocketConnection &lt;udsoncan.connections.IsoTPSocketConnection.Session&gt;`. Exists only for backward compatibility. """ passclass QueueConnection(BaseConnection): """ Sends and receives data using 2 Python native queues. - ``MyConnection.fromuserqueue`` : Data read from this queue when ``wait_frame`` is called - ``MyConnection.touserqueue`` : Data written to this queue when ``send`` is called :param mtu: Optional maximum frame size. Messages will be truncated to this size :type mtu: int :param name: This name is included in the logger name so that its output can be redirected. The logger name will be ``Connection[&lt;name&gt;]`` :type name: string """ def __init__(self, name=None, mtu=4095): BaseConnection.__init__(self, name) self.fromuserqueue = queue.Queue() # Client reads from this queue. Other end is simulated self.touserqueue = queue.Queue() # Client writes to this queue. Other end is simulated self.opened = False self.mtu = mtu def open(self): self.opened = True self.logger.info('Connection opened') return self def __enter__(self): return self def __exit__(self, type, value, traceback): self.close() def is_open(self): return self.opened def close(self): self.empty_rxqueue() self.empty_txqueue() self.opened = False self.logger.info('Connection closed') def specific_send(self, payload): if self.mtu is not None: if len(payload) &gt; self.mtu: self.logger.warning("Truncating payload to be set to a length of %d" % (self.mtu)) payload = payload[0:self.mtu] self.touserqueue.put(payload) def specific_wait_frame(self, timeout=2): if not self.opened: raise RuntimeException("Connection is not open") timedout = False frame = None try: frame = self.fromuserqueue.get(block=True, timeout=timeout) except queue.Empty: timedout = True if timedout: raise TimeoutException("Did not receive frame from user queue in time (timeout=%s sec)" % timeout) if self.mtu is not None: if frame is not None and len(frame) &gt; self.mtu: self.logger.warning("Truncating received payload to a length of %d" % (self.mtu)) frame = frame[0:self.mtu] return frame def empty_rxqueue(self): while not self.fromuserqueue.empty(): self.fromuserqueue.get() def empty_txqueue(self): while not self.touserqueue.empty(): self.touserqueue.get()class PythonIsoTpConnection(BaseConnection): """ Sends and receives data using a `can-isotp &lt;https://github.com/pylessard/python-can-isotp&gt;`_ Python module which is a Python implementation of the IsoTp transport protocol which can be coupled with `python-can &lt;https://python-can.readthedocs.io&gt;`_ module to interract with CAN hardware `can-isotp &lt;https://github.com/pylessard/python-can-isotp&gt;`_ must be installed in order to use this connection. See an :ref:`example&lt;example_using_python_can&gt;` :param isotp_layer: The IsoTP Transport layer object coming from the ``isotp`` module. :type isotp_layer: :class:`isotp.TransportLayer&lt;isotp.TransportLayer&gt;` :param name: This name is included in the logger name so that its output can be redirected. The logger name will be ``Connection[&lt;name&gt;]`` :type name: string """ mtu = 4095 def __init__(self, isotp_layer, name=None): BaseConnection.__init__(self, name) self.toIsoTPQueue = queue.Queue() self.fromIsoTPQueue = queue.Queue() self.rxthread = None self.exit_requested = False self.opened = False self.isotp_layer = isotp_layer assert isinstance(self.isotp_layer, isotp.TransportLayer) , 'isotp_layer must be a valid isotp.TransportLayer ' def open(self, bus=None): if bus is not None: self.isotp_layer.set_bus(bus) self.exit_requested = False self.rxthread = threading.Thread(target=self.rxthread_task) self.rxthread.start() self.opened = True self.logger.info('Connection opened') return self def __enter__(self): return self def __exit__(self, type, value, traceback): self.close() def is_open(self): return self.opened def close(self): self.empty_rxqueue() self.empty_txqueue() self.exit_requested=True self.rxthread.join() self.isotp_layer.reset() self.opened = False self.logger.info('Connection closed') def specific_send(self, payload): if self.mtu is not None: if len(payload) &gt; self.mtu: self.logger.warning("Truncating payload to be set to a length of %d" % (self.mtu)) payload = payload[0:self.mtu] self.toIsoTPQueue.put(bytearray(payload)) # isotp.protocol.TransportLayer uses byte array. udsoncan is strict on bytes format def specific_wait_frame(self, timeout=2): if not self.opened: raise RuntimeException("Connection is not open") timedout = False frame = None try: frame = self.fromIsoTPQueue.get(block=True, timeout=timeout) except queue.Empty: timedout = True if timedout: raise TimeoutException("Did not receive frame from user queue in time (timeout=%s sec)" % timeout) if self.mtu is not None: if frame is not None and len(frame) &gt; self.mtu: self.logger.warning("Truncating received payload to a length of %d" % (self.mtu)) frame = frame[0:self.mtu] return bytes(frame) # isotp.protocol.TransportLayer uses bytearray. udsoncan is strict on bytes format def empty_rxqueue(self): while not self.fromIsoTPQueue.empty(): self.fromIsoTPQueue.get() def empty_txqueue(self): while not self.toIsoTPQueue.empty(): self.toIsoTPQueue.get() def rxthread_task(self): while not self.exit_requested: try: while not self.toIsoTPQueue.empty(): self.isotp_layer.send(self.toIsoTPQueue.get()) self.isotp_layer.process() while self.isotp_layer.available(): self.fromIsoTPQueue.put(self.isotp_layer.recv()) time.sleep(self.isotp_layer.sleep_time()) except Exception as e: self.exit_requested = True self.logger.error(str(e))]]></content>
      <tags>
        <tag>python</tag>
        <tag>udsoncan</tag>
        <tag>uds</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[udsoncan-underlying protocol(connections)]]></title>
    <url>%2Fuds%2Fudsoncan.html</url>
    <content type="text"><![CDATA[Basics由于UDS是应用层协议，因此必须在数据传输协议上使用。目前的行业大多使用ISO-TP协议（ISO-15765）而不是CAN总线（ISO-11898）。 Controller Area Network（CAN）协议是一种link layer protocol，它通过8个字节的小块发送数据。 ISO-TP是一种transport protocol，允许传输更大的帧，通常最大为4095字节，尽管2016版本的标准使用超过32位定义的大小，理论上允许4GB一帧。 目前的ISO-15765协议分为4部分。 ISO-15765-2讲述了如何传输大帧，ISO-15765-3定义了如何将ISO-TP字段映射到UDS消息。 本工程仅讨论uds应用层。 How to通过Connection对象访问底层协议。用户可以通过继承BaseConnection对象来定义自己的Connection对象并实现abstract method。 与Connection对象一起使用的主要接口是： BaseConnection.send(data)12345# 将数据发送到底层传输协议Parameters: data (bytes, Request, Response) – The data or object to send. If a Request or Response is given, the value returned by get_payload() will be sent.Returns: None BaseConnection.wait_frame(timeout=2, exception=False)12345678910# 等待从底层传输协议接收数据帧Parameters: timeout (int) – The maximum amount of time to wait before giving up in seconds exception (bool) – Boolean value indicating if this function may return exceptions. When True, all exceptions may be raised, including TimeoutException When False, all exceptions will be logged as DEBUG and None will be returned. Returns: Received dataReturn type: bytes or None 可用的Connections一些Connections已经可用，只需从udsoncan.connections模块导入。这些Connections中的每一个都旨在解决特定用例。 PythonIsoTpConnection1class udsoncan.connections.PythonIsoTpConnection(isotp_layer, name=None) 发送和接收数据可以使用can-isotp Python模块，该模块是用Python实现IsoTp传输协议，IsoTp可以与python-can模块配合使用，与CAN硬件进行交互 必须安装can-isotp才能使用此connection。 举个例子：1234Parameters: isotp_layer (isotp.TransportLayer) – The IsoTP Transport layer object coming from the isotp module. name (string) – This name is included in the logger name so that its output can be redirected. The logger name will be Connection[&lt;name&gt;] SocketConnection1class udsoncan.connections.SocketConnection(sock, bufsize=4095, name=None) 通过socket发送和接收数据。 123456Parameters: sock (socket.socket) – The socket to use. This socket must be bound and ready to use. Only send() and recv() will be called by this Connection bufsize (int) – Maximum buffer size of the socket, this value is passed to recv() name (string) – This name is included in the logger name so that its output can be redirected. The logger name will be Connection[&lt;name&gt;] IsoTPSocketConnection1class udsoncan.connections.IsoTPSocketConnection(interface, rxid, txid, name=None, tpsock=None) 通过ISO-TP socket发送和接收数据。代码比SocketConnection更干净，但不提供其他功能。必须安装can-isotp模块才能使用此connection。 12345678910Parameters: interface (string) – The can interface to use (example: can0) rxid (int) – The reception CAN id txid (int) – The transmission CAN id name (string) – This name is included in the logger name so that its output can be redirected. The logger name will be Connection[&lt;name&gt;] tpsock (isotp.socket) – An optional ISO-TP socket to use instead of creating one. QueueConnection1class udsoncan.connections.QueueConnection(name=None, mtu=4095) 使用2个Python本机队列发送和接收数据。 MyConnection.fromuserqueue : Data read from this queue when wait_frame is called MyConnection.touserqueue : Data written to this queue when send is called 1234Parameters: mtu (int) – Optional maximum frame size. Messages will be truncated to this size name (string) – This name is included in the logger name so that its output can be redirected. The logger name will be Connection[&lt;name&gt;] Defining a new Connection如果以上所有Connection都不满足您的需求，您可以实现自己的Connection。 为了定义新Connection，必须实现如下5个函数，因为它们将由Client对象调用。 1234BaseConnection.open() Set up the connection object. Returns: None 1234BaseConnection.close() Close the connection object Returns: None 12345BaseConnection.specific_send(payload) The implementation of the send method. Parameters: payload (bytes) – Data to send eturns: None 1234567BaseConnection.specific_wait_frame(timeout=2) The implementation of the wait_frame method. Parameters: timeout (int) – The maximum amount of time to wait before giving up Returns: Received data Return type: bytes or None 1234BaseConnection.empty_rxqueue() Empty all unread data in the reception buffer. Returns: None]]></content>
      <tags>
        <tag>python</tag>
        <tag>udsoncan</tag>
        <tag>uds</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶第一课-Lesson 4：感知]]></title>
    <url>%2FSelf-Driving%20Car%20Fundamentals-Featuring%20Apollo%2F2018-07-18-Self-Driving%20Car%20Fundamentals-Featuring%20Apollo-lesson%204-Perception.html</url>
    <content type="text"><![CDATA[感知在本课中 我们将首先介绍计算机视觉的基本应用领域，然后我们将介绍机器学习、神经网络和卷积神经网络的基础知识。 我们将继续讨论感知模块在无人驾驶车中的具体任务，接下来将介绍 Apollo 感知模块的体系结构和传感器融合的相关主题。希望这会让你对无人驾驶感知系统有一个清晰认识 计算机视觉作为人类 你和我可以自动识别图像中的物体，甚至可以推断这些物体之间的关系。但是 对于计算机而言，图像只是红色、绿色和蓝色值的集合。如何将这些颜色值翻译为解读有意义的图像内容并不明显。 无人驾驶车有四个感知世界的核心任务。 检测 是指找出物体在环境中的位置 分类 是指明确对象是什么 跟踪 是指随时间的推移观察移动物体。如其他车辆、自行车和行人 语义分割意味着将图像中的每个像素与语义类别进行匹配。如道路、汽车或天空 我们可将 分类 作为作为研究计算机视觉一般数据流程的例子。 图像分类器是一种将图像作为输入并输出标识该图像的标签或“类别”的算法。例如 交通标志分类器查看停车标志并识别它是停车标志、让路标志、限速标志，还是其他类型的标志。分类器甚至可以识别行为。比如一个人是在走路 还是在跑步。 分类器有很多种，但它们都包含一系列类似的步骤。 首先 计算机接收类似摄像头等成像设备的输入，这通常被捕获为图像或一系列图像。 然后通过预处理发送每个图像预处理对每个图像进行了标准化处理。常见的预处理步骤包括调整图像大小或旋转图像或将图像从一个色彩空间转换为另一个色彩空间。例如从全彩到灰度。预处理可帮助我们的模型更快地处理和学习图像。 接下来 提取特征。特征有助于计算机理解图像。例如 将汽车与自行车区分开来的一些特征，汽车通常具有更大的形状 并且它有四个轮子而不是两个，形状和车轮将是汽车的显著特征。我们将在本课的后面详细讨论特征。 最后 这些特征被输入到分类模型中，此步骤使用特征来选择图像类别。例如 分类器可以确定图像是否包含汽车、自行车、行人或者根本不包含这样的对象。为了完成这些视觉任务，需要建立模型。模型是帮助计算机了解图像内容的工具，在计算机视觉中 无论经过训练的模型执行什么任务，它们通常在开始时将摄像头图像作为输入。 摄像头图像摄像头图像是最常见的计算机视觉数据。 以这张汽车照片为例，让我们看看计算机如何认为这实际上是一辆汽车的图像。 从计算机的角度来看，图像只是一个二维网格，也被称为矩阵。矩阵中的每个单元格都包含一个值，数字图像全部由像素组成，其中包含非常小的颜色或强度单位。 图像中的每个像素都只是一个数值，这些值构成了我们的图像矩阵。我们甚至可以改变这些像素值。我们可以通过为每个像素值添加一个标量整数来改变图像亮度，我们也可以向右移动每个像素值，我们还可以执行许多其他操作。通常 这些数字网格是许多图像处理技术的基础。多数颜色和形状转换都只是通过对图像进行数学运算以及逐一像素进行更改来完成。现在是一个将图像分解为二维灰度像素值网格的示例。 彩色图像是相似的 但更复杂一点，彩色图像被构建为值的三维立方体。每个立方体都有高度、宽度和深度，深度为颜色通道数量。大多数彩色图像以三种颜色组合表示，红色、绿色和蓝色，这些图像被称为 RGB 图像。对于 RGB 图像 深度为 3！因此 RGB 图像可以用一个薄盒子表示，将深度视为三重叠加的二维色层很有帮助。一层为红色，一层为绿色、一层为蓝色，它们一起构建了一个完整的彩色图像。 LiDAR 图像激光雷达传感器创建环境的点云表征，提供了难以通过摄像头图像获得的信息，如距离和高度。 激光雷达传感器使用光线 ，尤其是激光 来测量与环境中反射该光线的物体之间的距离。激光雷达发射激光脉冲并测量物体将每个激光脉冲反射回传感器所花费的时间。反射需要的时间越长 物体离传感器越远，激光雷达正是通过这种方式来构建世界的视觉表征。 你可以在此可视化视图中看到激光雷达的输出，激光雷达通过发射光脉冲来检测汽车周围的环境。蓝色点表示反射激光脉冲的物体，中间的黑色区域是无人驾驶车本身占据的空间。由于激光雷达测量激光束反射，它收集的数据形成一团点或 “点云”。 点云中的每个点代表反射回传感器的激光束，这些点云可以告诉我们关于物体的许多信息，例如其形状和表面纹理。通过对点进行聚类和分析，这些数据提供了足够的对象检测、跟踪或分类信息，在这里你可以看到在点云上执行的检测和分类结果。红点为行人 绿点表示其他汽车，正如你所看到的那样 激光雷达数据提供了用于构建世界视觉表征的足够空间信息。 计算机视觉技术不仅可以使用摄像头图像进行对象分类，还可以使用点云和其他类型的空间相关数据进行对象分类。 机器学习机器学习是使用特殊算法来训练计算机从数据中学习的计算机科学领域。通常 这种学习结果存放在一种被称为“模型”的数据结构中。有很多种模型，事实上 “模型”只是一种可用于理解和预测世界的数据结构。 机器学习涉及使用数据和相关的真值标记来进行模型训练。例如 可能会显示车辆和行人的计算机图像，以及告诉计算机哪个是哪个的标签，我会让计算机学习如何最好地区分两类图像，这类机器学习也称为 监督式学习，因为模型利用了人类创造的真值标记 你可以设想一个类似的学习过程，但这次使用的是没有真值标记的车辆与行人图像。在这种方法中 我们会让计算机自行决定，哪些图像相似 哪些图像不同，这被称为 无监督学习。我们在这不提供真值标记，而是通过分析输入的数据，计算机凭借自行学习找到区别。 另一种方法被称为 “半监督式”学习。它将监督学习和无监督学习的特点结合在一起，该方法使用少量的标记数据和大量的未标记数据来训练模型。 强化学习 是另一种机器学习，强化学习涉及允许模型通过尝试许多不同的方法来解决问题，然后衡量哪种方法最为成功。计算机将尝试许多不同的解决方案，最终使其方法与环境相适应。 例如 在模拟器中，强化学习智能体可训练汽车进行右转，智能体将在初始位置发动车辆，然后进行实验性驾驶，以多种不同的方向和速度。如果汽车实际完成了右转，智能体会提高奖励，即得分，这是针对导致成功结果的初始操作。起初 汽车可能无法找到执行转弯的方法，然而 就像人类那样，汽车最终会从一些成功的右转经验中学习，最后学会如何完成任务。 神经网络人工神经网络是通过数据来学习复杂模式的工具。神经网络由大量的神经元组成，正如人体神经系统的神经元那样，人工神经元负责传递和处理信息，也可以对这些神经元进行训练。 你可以将一些图像识别为车辆 无论它们是黑是白或大或小，你甚至可能不知道自己如何知道它们是车辆，也许是某些特征触发了你的反应，如车轮、车灯和车窗。 人工神经网络具有相似的运作方式，通过密集训练 计算机可以辨别汽车、行人、交通信号灯和电线杆。 当看到该图像时，你的大脑如何工作？你的大脑可能会将图像分为几部分，然后识别特征，如车轮、车窗和颜色 然后 大脑将使用这些特征对图像进行检测和分类。例如 在确定图像是否为汽车时，大脑可能不会认为颜色是关键特征 因为汽车有多种颜色，所以大脑会将更多权重放在其他特征上 并降低颜色的重要性。 同样地 神经网络也会从图像中提取许多特征但这些特征可能是我们人类无法描述或甚至无法理解的特征，但我们最终并不需要理解，计算机将 调整这些特征的权重以完成神经网络的最终任务，这就是深层神经网络的思维方式。 反向传播算法我们已经讨论过神经网络如何从数据中“学习”,那么你可能想知道这种学习如何发生。 学习有时称为训练，它由三步循环组成：前馈、误差测定和反向传播。 首先随机分配初始权重，即人工神经元的值。通过神经网络来馈送每个图像 产生输出值，这被称为前馈。 下一步为误差测定，误差是真值标记与与前馈过程所产生输出之间的偏差。 最后一步是反向传播，通过神经网络反向发送误差此过程类似前馈过程 只是以相反方向进行。 每个人工神经元都对其值进行微调，这是基于通过神经网络后向传播的误差。所有这些独立调整的结果 可生成更准确的网络 。 一个训练周期： 包括前馈、误差测定和反向传播还远远不够，为了训练网络 通常需要数千个这样的周期。但最终结果应该是：模型能够根据新数据做出准确预测。 卷积神经网络卷积神经网络 （CNN） 是 一种人工神经网络， 它对感知问题特别有效。CNN 接受多维输入，包括定义大多数传感器数据的二维和三维形状。 如果使用标准神经网络对图像进行分类，则需要通过一种方法将图像连接到网络的第一层，这属于一维。标准做法是通过将图像矩阵重塑为一个矢量，并在一个大行中连接所有列 将图像“展开”为一维像素阵列 。 然而 这种方法打破了图像中所嵌入的空间信息，如果图像中有车轮，则车轮中的所有像素将散布在整个像素阵列中。但我们知道 这些像素，以二维方式连接形成车轮。如果我们将其散布在一个维度上，神经网络很难从图像中提取车轮。 CNN 通过维持输入像素之间的空间关系来解决这个问题。具体来说 CNN 通过将过滤器连续滑过图像来收集信息，每次收集信息时，只对整个图像的一小部分区域进行分析，这被称为 “卷积”。 当我们在整个输入图像上对一个过滤器进行“卷积”时，我们将该信息与下一个卷积层相关联。例如 CNN 可以识别第一个卷积层中的基本边缘和颜色信息，然后 通过在第一层上卷积新过滤器，CNN 可以使用边缘和颜色信息，来归纳更复杂的结构 如车轮、车门和挡风玻璃。而另一个卷积可使用车轮、车门和挡风玻璃识别整个车辆。最后 神经网络可使用这一高阶信息对车辆进行分类。 人们通常不太清楚 CNN 如何解读图像，CNN 有时会侧重于图像中令人惊讶的部分，但这也是深度学习的神奇之处。CNN 根据其任务查找真正需要的特征，任务可能是图像检测、分类、分割或其他类型的目标。 检测与分类在感知任务中,首先想到的是障碍物检测和分类。 在驾驶过程中会遇到许多障碍物，静态障碍物包括墙壁、树木、杆子和建筑物。动态障碍物包括行人、自行车和各种汽车。 计算机首先需要知道这些障碍物的位置，然后对它们进行分类。在路中行驶的无人驾驶车可能会探测到许多不同的物体，汽车根据所感知的物体类型，来确定路径和速度。如果感知到前方有一辆自行车，汽车可能会决定减速和变道 以便安全驶过自行车。但是 如果感知到前方有另一辆车，并预测到前方车辆也将以接近限速的速度行驶。无人驾驶车可能会保持其速度和车道。 另一个示例为 交通信号灯检测分类。首先 我们将使用计算机视觉对图像中的交通信号灯进行定位。然后 我们可以根据灯光显示颜色对交通信号灯进行分类。 在无人驾驶车辆中，我们使用什么算法来对障碍物进行检测和分类？我们可以先使用检测 CNN 来查找图像中的对象的位置，在对图像中的对象进行定位后，我们可以将图像发送给另一个 CNN 进行分类。 我们也可以使用单一 CNN 体系结构对对象进行检测和分类。一种通常的做法为在单个网络体系结构的末端附加几个不同的“头”，一个头可能执行检测，另一个则可能执行分类。 一个经典的体系结构为 R-CNN 及其变体 Fast R-CNN 和 Faster R-CNN、YOLO 和 SSD 是具有类似形式的不同体系结构。 tracking跟踪在检测完对象后 我们需要追踪它们。 追踪的意义是什么？如果我们对每个帧中的每个对象进行检测并用边界框对每个对象进行标识。 那么跨帧追踪对象会带来哪些好处？首先 追踪在检测失败时是至关重要的。如果你在运行检测算法时，对象被其他对象遮挡一部分，则检测算法可能会失败。追踪可以解决遮挡问题。另一个原因在于追踪可以保留身份。障碍物检测的输出为包含对象的边界框，但是 对象没有与任何身份关联，单独使用对象检测时，计算机不知道一个帧中的哪些对象与下一帧中的哪些对象相对应。 该任务对人类来说很简单 但对汽车来说很困难。追踪的第一步为确认身份，通过查找特征相似度最高的对象，我们将在之前的帧中检测到的所有对象与在当前的帧中检测到的对象进行匹配。对象具有各种特征，有些特征可能基于颜色 而另一些特征可能基于形状，计算机视觉算法可以计算出复杂的图像特征，如局部二值模式和方向梯度直方图。当然 我们也需要考虑连续视频帧中，两个障碍物之间的位置和速度。由于两个帧之间的对象位置和速度没有太大变化，该信息也可以帮助我们快速找到匹配的对象。在确定身份后 我们可以使用对象的位置，并结合预测算法以估计在下一个时间步的速度和位置，该预测可帮助我们识别下一帧中的相应对象。 segmentation 语义分割语义分割涉及对图像的每个像素进行分类。它用于尽可能详细地了解环境，并确定车辆可驾驶区域。 语义分割依赖于一种特殊类型的 CNN，它被称为全卷积网络 或 FCN。FCN 用卷积层来替代传统 CNN 体系结构末端的平坦层。现在 网络中的每一层都是卷积层，因此其名称为“全卷积网络”。 FCN 提供了可在原始输入图像之上叠加的逐像素输出，我们必须考虑的一个复杂因素是大小。在典型的 CNN 中 经过多次卷积之后，所产生的输出比原始输入图像小得多。 然而 为了分割像素，输出尺寸必须与原始图像的尺寸相匹配，为了达到该目的 我们可以对中间输出进行上采样处理，直到最终输出的大小与原始输出图像的大小相匹配，网络的前半部分通常被称为编码器。因为这部分网络对输入图像的特征进行了提取和编码，网络的后半部分通常被称为解码器，因为它对这些特征进行了解码 并将其应用于输出。 Apollo 感知Apollo 开放式软件栈可感知障碍物、交通信号灯和车道。对于三维对象检测，Apollo 在高精度地图上使用 感兴趣区域 (ROI)来重点关注相关对象。 Apollo 将 ROI 过滤器应用于点云和图像数据，以缩小搜索范围并加快感知。然后 通过检测网络馈送已过滤的点云，输出用于构建围绕对象的三维边界框，最后 我们使用被称为 检测跟踪关联 的算法来跨时间步识别单个对象。 该算法先保留在每个时间步要跟踪的对象列表，然后在下一个时间步中找到每个对象的最佳匹配。对于交通信号灯的分类,Apollo 先使用高精度地图来确定前方是否存在交通信号灯,如果前方有交通信号灯,则高精度地图会返回灯的位置,这侧重于摄像头搜索范围,在摄像头捕获到交通信号灯图像后,Apollo 使用检测网络对图像中的灯进行定位,然后 Apollo 从较大的图像中提取交通信号灯。Apollo 将裁剪的交通灯图像提供给分类网络，以确定灯颜色。如果有许多灯，则系统需要选择哪些灯与其车道相关。 Apollo 使用 YOLO 网络，来检测车道线和动态物体。 其中包括车辆、卡车、骑自行车的人和行人，在经过 YOLO 网络检测后，在线检测模块会并入来自其他传感器的数据，对车道线预测进行调整，车道线最终被并入名为“虚拟车道”的单一数据结构中。同样 也通过其他传感器的数据对 YOLO 网络所检测到的动态对象进行调整以获得每个对象的类型、位置、速度和前进方向。虚拟通道和动态对象均被传递到规划与控制模块。 传感器数据比较 感知通常依赖于摄像头、激光雷达和雷达。该图显示了这三种传感器的优缺点，绿色代表性能良好，黄色代表混合性能，红色代表性能不佳。 摄像头非常适用于分类，在 Apollo 中 摄像头主要用于交通信号灯分类 以及车道检测。 激光雷达的优势在于障碍物检测，即使在夜间 在没有自然光的情况下，激光雷达仍能准确地检测障碍物。 雷达在探测范围和应对恶劣天气方面占优势 通过融合这三种传感器的数据，可实现最佳聚合性能，这被称为“传感器融合” 雷达与激光雷达雷达已经在汽车上使用很多年，在各种系统中都需要雷达，如自适应巡航控制、盲点警告、碰撞浸膏和碰撞预防系统等。尽管雷达技术已经成熟，它仍在不断进步，作用不断提升。其他传感器测量速度的方法是计算两次读数之间的差距，而雷达则通过多普勒效应来直接测量速度。多普勒效应根据对象在远离还是接近你，测量出雷达的频率变化。就像消防车警报器一样，当车辆正在远离你和驶向你时，听起来声是不一样的。多普勒效应对传感器融合至关重要。因为它可以把速度作为独立的测量参数，从而提升了融合算法的收敛速度。雷达还可以生成环境的雷达地图，进而实现定位。因为雷达波在坚硬表面会回弹。因此，它可以直接测量对象距离，无需在视线范围内也可以。雷达可以看到其他车辆底部。并发现可能会被阻挡的建筑物和对象。在车上的所有传感器中，雷达是至不容易受雨雾影响的。而且视野宽阔，可达 150 度，距离可达200 多米。与激光雷达和摄像头相比，雷达分辨率较低，尤其是在垂直方向，分辨率非常有限。分辨率低意味着来自静态物体的反射可能产生问题。例如，街道上检修孔盖或汽水罐，可能产生很高的雷达反射率，但他们并不大。我们将其称为雷达杂波。因此，当前的车载雷达通常会忽视静态物体。 激光雷达是激光探测与测量的简称，而雷达则谁无线电探测与测量的简称。雷达使用无线电波，而激光雷达则使用红激光束来确定传感器和附近对象的距离。目前的激光雷达大多使用 900 纳米光波长度的光源。但部分激光雷达使用的光波长度更长，在雨雾中性能更好。当前的激光雷达使用旋转座架发射激光，扫描周边环境。激光室脉冲式的，脉冲被对象反射，然后返回一个点云，来代表这些物体。激光雷达的空间分辨率远远高于雷达。因为激光束越聚焦，垂直方向的扫描层数量就越多，因此每层的激光雷达的密度也越高。目前，激光雷达还不能直接测量对象的速度，必须使用两次或多次扫描之间的位置差来确定。激光雷达受天气和传感器清洁程度影响也很大，因此需要保持清洁。它们块头也比其他传感器更大，因此也很难安装，除非你只想在车顶安装一个大的激光扫描器。 感知融合策略Apollo 使用激光雷达和雷达来检测障碍物。用于融合输出的主要算法为卡尔曼滤波。 卡尔曼滤波有两个步骤。第一步为预测状态，第二步是更新测量结果。 设想我们正在跟踪一名行人，这里的状态表示行人的位置和速度，从已经掌握的行人状态开始。我们使用这些信息来执行卡尔曼滤波的第一步，即预测行人在将来的状态。 下一步为误差结果更新，我们使用新的传感器来更新我们所认为的行人状态，卡尔曼滤波算法是预测和更新步骤的无限循环。 实际上有两种测量结果更新步骤：同步和异步。同步融合同时更新来自不同传感器的测量结果，而异步融合则逐个更新所收到的传感器测量结果。传感器融合可提高感知性能 因为各传感器相辅相成，融合也可以减少跟踪误差，所以我们可以更加确信，对道路上其他物体位置的预测。]]></content>
      <categories>
        <category>self-driving</category>
      </categories>
      <tags>
        <tag>无人驾驶 Apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶第一课-Lesson 3：定位]]></title>
    <url>%2FSelf-Driving%20Car%20Fundamentals-Featuring%20Apollo%2F2018-07-14-Self-Driving%20Car%20Fundamentals-Featuring%20Apollo-lesson%203-Location.html</url>
    <content type="text"><![CDATA[定位定位是让无人驾驶车知道自身确切位置的方法,这是一个美妙而富有挑战性的任务. 定位简介现在我们假设你有一张全球的高精度地图，定位的任务是确定你的车辆在这张高精度地图上的位置。 在我的日常生活中，我一直使用手机 GPS 来确定自己的位置，但 GPS 对于无人驾驶车来说不够精确。大多数时候，GPS 的精度在1-3米间，这对于无人驾驶车来说太不精确了。 在一些情况下比如我们被高楼、山脉围绕或位于峡谷内，GPS 的精度可能只有10 米、甚至只有 50 米。 由于我们无法完全信任 GPS，因此我们必须找到另一种方法来更准确地确定车辆在地图上的位置。最常用的方法是将汽车传感器所看到的内容与地图上所显示的内容进行比较。 车辆传感器可以测量车辆与静态障碍物之间的距离，如树木、电线杆、路标和墙壁等。我们在车辆自身的坐标系中测量这些距离、这些静态障碍物的方向。随着车辆转弯，车辆自身的坐标系必然与地图坐标系不一致，车辆的坐标和地图坐标系可能均取决于手机导航系统中的设置。 为估计车辆在地图上的位置，我们将传感器的地标观测值与这些地标在地图上的位置进行匹配。地图自带坐标系，无人驾驶软件必须将传感器的测量值从车辆坐标系转换为地图坐标系，反之亦然。执行这类转换是解决定位问题的关键步骤。 我来做一个总结：对于定位，车辆将其传感器识别的地标与其高精度地图上存在的地标进行比对。为了进行该比对，必须能够在它自身坐标系和地图坐标系之间转换数据。然后，系统必须在地图上以十厘米的精度确定车辆的精确位置。 定位提供了许多可供选择的方法，每种方法都有各自的优缺点。我们将探讨几种常见的无人驾驶车定位方法 如GNSS RTK、惯性导航、LiDAR 定位和视觉定位 最后 我们将了解 Apollo 框架是如何解决定位问题的。 Sebastian介绍定位什么是定位比如机器人需要知道它在哪里，这包括 X、Y 坐标位置、航向等信息。精确定位，我们要精确到 以准确地知道我们在哪个地方以及我们在车道内的哪个位置。 为什么要追求精确定位呢？因为如果我们确切地知道我们在哪里，如果没有其他汽车和行人等，我们几乎可以闭着眼开车。 所以要做一个关于定位的全景图，它将涉及不同类型的传感器也就是我们所谓的惯性感知，此外，还有不同类型的外部传感器包括摄像头、激光雷达等。 GNSS RTK如果在野外迷路 你会怎么做？ 假如你看到自己离一棵树 75 米远,你可能在哪里?你只知道自己位于离树 75 米远的地方,更确切地说 你位于一个以树为中心 半径为 75 米的圆上。 现在你看到了一个离自己 64 米远的房子，你知道自己现在在哪里吗？ 信不信由你 你可能不知道。你知道自己位于两个圆的交点处，但可能有两个交点，你不知道自己位于哪个交点上。 现在假设你看到了第三个路标，即路灯 经过测量 你发现自己离路灯 55 米远，你总算知道了相对于这些地标的确切位置。 如果你有一张地图，里面注明了这些地标在世界上的位置，你就知道了自己在世界上的确切位置,该过程被称为 三角测量。 我们刚刚讲解的示例有两个维度，想象一下 我们试图在地球表面上进行三维定位。我们将使用传送它们与我们之间距离的卫星，而不是我们可以看到的地标，这就是 GPS 的工作原理。 如果我们在地球上某一处，我们至少需要有多少卫星才能知道我们在哪里？ 答案与二维平面中的问题相同。 然而，实际生活中，GPS 使用另外一颗卫星来确定海拔高度。所以，每时每刻总共有 4 颗卫星确定你的位置。 GPS 即全球定位系统，这是一种由美国政府开发并在全球范围内运营的卫星导航系统。这类系统的通用名称为全球导航卫星系统或 GNSS。GPS 是使用最广泛的 GNSS 系统。 GPS 分为三部分。第一部分是卫星。在任何特定时间 大约有 30 颗 GPS 卫星在外层空间运行。它们各自距离地球表面约 2 万公里。 该系统的第二部分由世界各地的控制站组成。控制站用于监视和控制卫星，其主要目的是让系统保持运行，并验证 GPS 广播信号的精确度 系统的最后一部分是 GPS 接收器。GPS 接收器存在于手机、电脑、汽车、船只以及许多其他设备中。如果周围没有高楼等障碍物，并且天气良好，那么无论你身在何处，GPS 接收器每次应至少检测到四颗 GPS 卫星。 GPS 接收器实际上并不直接探测你与卫星之间的距离，它首先测量信号的飞行时间，也就是说 信号从卫星传播到你的 GPS 接收器需要多长时间？通过将光速乘以这个飞行时间，来计算离卫星的距离。由于光速的值很大，即使是少量的时间误差也会在距离计算中造成巨大的误差。因此 为进一步减小误差 每颗卫星都配备了高精确度的原子钟。 我们可以使用 实时运动定位（或 RTK）。RTK 涉及在地面上建立几个基站，每个基站都知道自己精确的“地面实况”位置。但是 每个基站也通过 GPS 测量自己的位置，已知的“地面实况”位置，与通过 GPS 测量的位置之间的偏差为 GPS 测量结果中的误差. 然后 将这个误差传递给其他 GPS 接收器,以供其调整自身的位置计算。在 RTK 的帮助下，GPS 可以将定位误差限制在 10 厘米以内。但是 仍存在高楼和其他障碍物可能阻挡 GPS 信号的问题，这使定位变得困难 或根本无法定位。 GPS 的另一个缺点在于它的更新频率很低，大约为 10 赫兹 或每秒更新 10 次，由于无人驾驶车在快速移动，我们可能需要更频繁地更新位置。 惯性导航我们来学习一种被称为惯性导航的定位方法。 假设一辆汽车正以恒定速度直线行驶，如果我为你提供了汽车的初始位置、速度、行驶时长。你可以告诉我汽车现在处于什么位置吗？即从初始位置开始，然后速度乘以时间。$$s=s_0+vt$$ 接下来 让我们尝试一个更难的问题。还是同样的问题 但不是初始位置和速度，而是 我向你提供初始速度和加速度，稍后你能告诉我车辆的速度吗？$$v=v_0+at$$ 我们可以使用加速度、初始速度和初始位置来计算汽车在任何时间点的车速和位置。 但是 这又引出了另一个问题：我们该如何测量加速度？ 我们需要一个名为三轴加速计的传感器。有三种不同类型的三轴加速度计，它们采用不同的方法，但共同的目标是精确测量加速度。 然而 加速度计本身，不足以计算我们的位置和速度。加速度计根据车辆的坐标系记录测量结果，我们需要知道如何将这些测量值转换为全局坐标系，这种转换需要另一个名为陀螺仪的传感器。 三轴陀螺仪的三个外部平衡环一直在旋转，但三轴陀螺仪中的旋转轴始终固定在世界坐标系中，我们计算车辆在坐标系中的位置是通过测量旋转轴和三个外部平衡环的相对位置来计算的。 加速度计和陀螺仪是惯性测量单元 (或 IMU) 的主要组件。IMU 的一个重要特征在于它以高频率更新，其频率可达到 1000 赫兹，所以 IMU 可以提供接近实时的位置信息。 遗憾的是 惯性测量单元的缺点在于其运动误差随时间增加而增加，我们只能依靠惯性测量单元，在很短的时间范围内进行定位 但是 我们可以结合 GPS 和 IMU 来定位汽车。一方面 IMU 弥补了 GPS 更新频率较低的缺陷，另一方面 GPS 纠正了 IMU 的运动误差。 但是 即使将 GPS 和 IMU 系统相结合，也不能完全解决我们的定位问题。如果我们在山间行驶，或城市峡谷中，或者最糟糕的是在地下隧道中行驶。那么我们可能会长时间没有 GPS 更新，这会让整个定位面临失败风险。 LiDAR定位利用激光雷达 我们可以通过点云匹配来对汽车进行定位。该方法将来自激光雷达传感器的检测数据，与预先存在的高精度地图连续匹配。通过这种比较，可获知汽车在高精度地图上的全球位置和行驶方向。 有许多算法可用于匹配点云。 迭代最近点（或 ICP）是一种方法。假设我们想对两次点云扫描进行匹配，对于第一次扫描中的每个点，我们需要找到另一次扫描中最接近的匹配点。最终我们会收集到许多匹配点对，我们把每对点之间的距离误差相加，然后计算平均距离误差。我们的目标是通过点云旋转和平移来最大限度地降低这一平均距离误差，一旦我们最大限度地降低了点云之间的误差，我们就可以在传感器扫描和地图之间找到匹配，我们将通过传感器扫描到的车辆位置转换为全球地图上的位置，并计算出在地图上的精确位置。 滤波算法是另一种LiDAR 定位方法。滤波算法可消除冗余信息，并在地图上找到最可能的车辆位置。Apollo 使用了 直方图滤波算法，该方法有时也被称为 误差平方和算法（或 SSD）。为了应用直方图滤波，我们将通过传感器扫描的点云滑过地图上的每个位置。在每个位置我们计算扫描的点与高精度地图上的对应点之间的误差或距离，然后对误差的平方求和。求得的和越小，扫描结果与地图之间的匹配越好。该示例显示一些对齐较好的点 以红色表示，以及一些对齐较差的点 以蓝色表示。在该示例中 绿色表示中等对齐。 卡尔曼滤波是另一种LiDAR 定位方法。卡尔曼滤波是一种算法,用于根据我们在过去的状态和新的传感器测量结果预测我们当前的状态。具体来说 卡尔曼滤波使用了预测更新周期。首先 我们根据之前的状态以及对移动距离和方向的估计，来估计或“预测”我们的新位置。当然 我们的运动估计并不完美，所以需要通过使用传感器测量我们的位置并加以纠正。一旦用传感器测量了我们的新位置，我们便可以使用概率规则 ，将也不完美的传感器测量结果与我们现有的位置预测结合起来，我们会永远遵循这个预测更新周期，只要我们需要对车辆进行定位，先预测我们的新位置 然后用传感器测量我们的位置。 LiDAR 定位的主要优势在于稳健性。只要从高精度地图开始 并且存在有效的传感器，我们就始终能够进行定位。 主要缺点在于难以构建高精度地图,并使其保持最新。事实上 几乎不可能让地图完全保持最新，因为几乎每个地图均包含瞬态元素，汽车和行人 甚至停放的汽车，在我们下次驾车驶过时都会消失，街道上的垃圾会被吹走，世界上的许多元素都在不断发生变化。 视觉定位图像是要收集的最简单的数据类型。摄像头便宜且种类繁多，还易于使用，我们可以使用图像来定位汽车吗？ 通过图像实现精确定位非常困难，实际上 摄像头图像通常与来自其他传感器的数据相结合，以准确定位车辆。但 将摄像头数据与地图和 GPS 数据相结合比单独使用摄像头图像进行定位的效果更好。 假设一辆车正在路上行驶 它感知到右边有一棵树，但是 地图显示道路右侧有几棵树，全部位于不同的位置，我们如何知道车辆现在看到哪棵树？ 我们可以用概率来解决这个问题。想象一下 我们位于道路上许多不同点中的任意一点处，使用概率来确定哪个点，最可能代表我们的实际位置。 我们知道在右边看到一棵树，我们假设从一些点可以看到右边有一棵树 而从另一些点则看不到，当然 我们很可能位于可以看到右边有一棵树的地方。我们可以排除在地图上无法看到右边那棵树的点。 我们可以在开车的同时继续观察周边世界。想象一下 我们开车前行 然后观察到右边的另一棵树。在观察地图上的其余点之后。我们发现仅在少数几个位置，会发现车辆右侧有成排的两棵树，我们当然最有可能位于这些位置之一，所以我们可以排除所有其他位置。 我们继续该过程 通过观察结果、概率和地图来确定我们最可能的位置。该过程被称为粒子滤波。 因为我们使用粒子或点来估计最可能的位置,当然 树木在许多道路上比较稀少，但是 车道线在许多道路上却很常见，可以使用相同的粒子滤波原理对车道线进行拍照，然后使用拍摄的图像来确定车辆在道路中的位置。可以将道路摄像头图像与地图进行比较，我们的摄像头图像与地图的某些部分匹配得很好，但与地图的其他部分匹配得没那么好。 这是视觉车道线匹配的一个示例。蓝色代表地图上两个不同位置的车道线。我们想确定哪个位置更有可能是我们所处的位置。红色代表车辆摄像头观察到的车道线，红线与右侧蓝线的匹配度要比与左侧蓝线的匹配度高得多，因此 我们更有可能位于与右侧图像对应的地图位置上。 视觉定位的优点在于图像数据很容易获得，缺点在于缺乏三维信息和对三维地图的依赖。 Apollo定位Apollo 使用基于 GPS、IMU 和激光雷达的多传感器融合定位系统。这种融合方法利用了不同传感器的互补优势，它也提高了稳定性和准确性， Apollo 定位模块依赖于 IMU、GPS、激光雷达、雷达和高精度地图。这些传感器同时支持 GNSS 定位和LiDAR 定位。GNSS 定位输出位置和速度信息，LiDAR 定位输出位置和行进方向信息。 融合框架通过卡尔曼滤波将这些输出结合在一起，卡尔曼滤波建立在两步预测测量周期之上。在 Apollo 中 惯性导航解决方案用于卡尔曼滤波的预测步骤，GNSS 和 LiDAR 定位用于卡尔曼滤波的测量结果更新步骤。 点击 这里 了解卡尔曼滤波的工作原理。 关于 Apollo 定位的论文，可以查阅 “Robust and Precise Vehicle Localization based on Multi-sensor Fusion in Diverse CityScenes, ICRA, 2018”.]]></content>
      <categories>
        <category>self-driving</category>
      </categories>
      <tags>
        <tag>无人驾驶 Apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶第一课-Lesson 2：高精度地图]]></title>
    <url>%2FSelf-Driving%20Car%20Fundamentals-Featuring%20Apollo%2F2018-07-12-Self-Driving%20Car%20Fundamentals-Featuring%20Apollo-lesson%202-HD%20Maps.html</url>
    <content type="text"><![CDATA[高精度地图导航地图(Navigation Map)VS高精度地图(HD Map)高精度地图是当前无人驾驶车技术不可或缺的一部分。 高精度地图包含大量的驾驶辅助信息，最重要的信息是道路网的精确三维表征。例如 ：交叉路口布局和路标位置。高精度地图还包含很多语义信息，地图可能会报告交通灯上不同颜色的含义，它也可能指示道路的速度限制以及左转车道开始的位置。 高精度地图最重要的特征之一是精度。手机上的导航地图只能达到米级精度，高精度地图使车辆能够达到厘米级的精度，这对确保无人驾驶车辆的安全性至关重要 地图与定位可以将定位与拼图进行比较。如果我同时为你提供地图和同一张地图的一小块，你能否在地图上找到这一小块的确切位置？试一试，正如拼图游戏那样。无人驾驶车辆需要知道它在地图上的确切位置，首先 车辆可能会寻找地标。我们可以使用从各类传感器收集的数据，如摄像机图像数据以及激光雷达收集的三维点云数据来查找地标。车辆将其收集的数据与其高精度地图上的已知地标进行比较. 这一匹配过程是需要预处理、坐标转换和数据融合的复杂过程 。 预处理消除了不准确或质量差的数据, 坐标变换将来自不同视角的数据转换为统一的坐标系 借助数据融合 可将来自各种车辆和传感器的数据合并 一旦无人驾驶车高度精确地确定了其位置,定位任务也就完成了. 整个定位过程取决于地图. 正因为如此 车辆需要高精度地图 以便知道它处于什么位置 地图与感知 无人驾驶车也可以使用高精度地图来帮助感知。人有眼睛和耳朵，但都有距离限制，我们无法看到或听到太远的事物。无人驾驶汽车的传感器也会受到类似限制摄像机、激光雷达和雷达探测物体的能力，在超过一定距离后都会受到限制。在恶劣的天气条件下或在夜间，传感器识别障碍物的能力可能会受到进一步限制另外 当汽车遇到障碍物时，传感器无法透过障碍物来确定障碍物后面的物体。在这种情况下 高精度地图有很大帮助。即使传感器尚未检测到交通信号灯它也可以将交通信号灯的位置提供给软件栈的其余部分，这可以帮助汽车做下一个决策。 另一个好处在于 地图可帮助传感器缩小检测范围。例如 高精度地图可能会告知我们，在特定位置寻找停车标志。传感器就可以集中在该位置检测停车标志。这被称为感兴趣区域或 ROI，ROI 可帮助我们提高检测精确度和速度，并节约计算资源。 地图与规划正如定位和感知软件依赖于高精度地图那样，规划软件也是如此。 高精度地图可帮助车辆找到合适的行车空间，它还可以帮助规划器确定不同的路线选择，并帮助预测软件预测道路上其他车辆在将来的位置。 例如 高精度地图可帮助车辆识别车道的确切中心线，这样车辆可以尽可能地靠近中心行驶。 在具有低速限制、人行横道或减速带的区域，高精度地图使车辆能够提前查看 并预先减速 更重要的是 如果前方有障碍物，车辆可能需要变道，高精度地图可帮助车辆缩小选择范围，以便选择最佳方案。 appllo高精度地图高精度地图的构建由五个过程组成：数据采集、数据处理、对象检测、手动验证和地图发布. 数据采集 是一项庞大的密集型任务.无人驾驶车需要其地图始终保持最新状态。大量的调查车辆可确保每次道路发生改变时，地图均会得到快速更新。调查车辆使用了多种传感器 如 GPS、惯性测量单元、激光雷达和摄像机。Apollo 定义了一个硬件框架将这些传感器集成到单个自主系统中，通过支持多种类的传感器，Apollo 可以收集各类数据，将这些数据融合，最终生成高精度地图。 数据处理指的是 Apollo 如何对收集到的数据进行整理、分类和清洗以获得没有任何语义信息或注释的初始地图模板 对于对象检测 Apollo 团队使用人工智能来检测静态对象，并对其进行分类，其中包括车道线、交通标志 甚至是电线杆 手动验证可确保自动地图创建过程正确进行并及时发现问题。Apollo 软件使手动验证团队能够高效标记和编辑地图。 在经过数据采集、数据处理、对象检测和手动验证之后 地图即可发布。除发布高精度地图外，Apollo 还发布了采用自上而下视图的相应定位地图以及三维点云地图]]></content>
      <categories>
        <category>self-driving</category>
      </categories>
      <tags>
        <tag>无人驾驶 Apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶第一课-Lesson 1：无人驾驶概览]]></title>
    <url>%2FSelf-Driving%20Car%20Fundamentals-Featuring%20Apollo%2F2018-07-11-Self-Driving%20Car%20Fundamentals-Featuring%20Apollo-lesson%201-%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E6%A6%82%E8%A7%88.html</url>
    <content type="text"><![CDATA[无人驾驶概览Udacity无人驾驶项目负责人David Silver 表示： “在全球无人驾驶技术人才奇缺的宏观现实下，如果你对无人驾驶汽车感兴趣，或者有志于从事无人驾驶开发的工作，现在就是最好的时机 你将学到什么 Apollo 无人驾驶开源平台的主要部分 high-definition maps 高精度地图 无人驾驶车的核心模块——高精度地图，几乎支持着软件栈的所有其他模块，包括定位、感知、预测和规划 localization 定位 在定位课程中，将讨论汽车如何确定它所处的位置。这比预想得更难！汽车利用激光和雷达数据，将这些传感器感知内容与高分辨率地图进行对比，这种对比使汽车能够以个位数厘米级精度进行自定位 perception 感知 在感知课程中，将了解无人驾驶车如何感知这个世界。深度学习是一个重要且强有力的感知工具，卷积神经网络构成深度学习分支，对感知任务至关重要。如分类、检测和分割，这些方法适用于几种不同无人驾驶车传感器的数据来源，包括摄像头、雷达和激光雷达 prediction 预测 我们将概述几种不同的方式，用于预测其他车辆或行人可能如何移动。一种方法称为递归神经网络。可对其他物体随时间的运动进行跟踪，并使用该时间序列数据预测未来 planning 规划 规划课程将涵盖如何将预测与路线相结合以生成车辆轨迹，规划是构建无人驾驶车最困难的部分之一 control 控制 控制课程展示了如何使用转向、油门和制动来执行规划轨迹。我们将阐释几种不同类型的控制器，类型从简单到愈加复杂，而性能却从弱到强 希望：在完成这门课时，你将了解无人驾驶车的基本工作原理。我希望你开始这段学习之旅时，像我第一次开始学习无人驾驶车时那样激动 Apollo核心模块在课程开始之前, 你可以先阅读Github中以下模块的Readme, 来对无人驾驶技术的架构有一个总体的了解~ 定位 感知 预测 路由 规划 控制 为什么我们需要无人驾驶车？最重要的原因是安全 无人车等级划分汽车工程师已建立并确定了 6 个等级的无人驾驶车 0 级为基本等级，驾驶员是系统的唯一决策者 1 级为驾驶员辅助，车辆为驾驶员提供转向或加速支持如巡航控制 2 级为部分自动化，车辆自动控制几项功能如自动巡航控制和车道保持 3 级为有条件的自动化，车辆自主驾驶 4 级为高度自动化，车辆控制、驾驶方面不期望驾驶员的介入 5 级为最高级别，完全自动化，应与人类驾驶员的水平一样高或比其更高 How self-driving cars work无人驾驶车包括五个核心部件 计算机视觉 就是我们通过摄像头图像弄清楚我们周围的世界是怎样的 传感器融合 是我们合并来自其他传感器的数据， 如激光和雷达，从而更加深入地了解我们周围的环境 只要我们对周围的世界有了深刻的理解，就可以使用 定位 来精确地确定我们在那个世界所处的位置 弄清楚where we are in the world and what the world looks like，就可以使用 路径规划 来绘制路线 控制 就是我们为了让汽车沿着我们在路径规划期间建立的轨道，如何转动方向盘并打开油门 然后踩刹车 Apollo 技术框架由四个层面组成参考车辆平台、参考硬件平台、开源软件平台和云服务平台 参考车辆与硬件平台如果我们想要打造一辆无人驾驶车。首先要开发一款可通过电子控制的基础车辆，而不仅仅是通过实体方向盘、油门踏板和刹车踏板来控制，这种类型的车辆具有特殊的名称：线控驾驶车辆 Apollo 无人驾驶车有几个不同的传感器。 控制器区域网络（或 CAN），是车辆的内部通信网络，计算机系统通过 CAN 卡连接汽车内部网络，发送加速、制动和转向信号。 全球定位系统（或 GPS），通过绕地卫星接收信号，这些信号可帮助我们确定所处位置。 惯性测量装置（或 IMU），测量车辆的运动和位置，是通过跟踪位置、速度、加速度和其他因素。 激光雷达 (LiDAR) 由一组脉冲激光器组成Apollo 使用的激光雷达可 360 度扫描车辆周围，这些激光束的反射形成了软件可用于了解环境的点云 摄像头捕获图像数据，我们可以使用计算机视觉来提取这些图像的内容并了解周围的环境。例如 因为摄像头可以感知颜色，我们用它们来检测和了解交通灯 雷达也用于检测障碍物，雷达分辨率低，难以分辨雷达检测到了哪种障碍物，但雷达的优势在于经济实惠，适用于各种天气和照明条件，雷达特别擅长测量其他车辆的速度。 下图说明如何将主要硬件组件安装到车辆上,包括摄像头、雷达、激光雷达、GPS-IMU 和 IPC 开源软件栈软件层分为三个子层:实时操作系统(real-time operating system(ROTS))、运行时框架(Runtime Framework) 和 应用程序模块层(a layer of application modules) 实时操作系统（或 RTOS）可确保在给定时间内完成特定任务。“实时”是指无人驾驶车的操作系统能够及时进行计算、分析并执行相应的操作。实时性能是确保系统稳定性和驾驶安全性的重要要求。 Apollo RTOS 是 Ubuntu Linux 操作系统与 Apollo 内核相互结合的成果。Ubuntu 是业内顶级 Linux 发行版之一，也是最流行的云操作系统，然而 原始 Ubuntu 系统并非实时操作系统，通过加入 Apollo 设计的内核 我们可以使其成为一个 RTOS。 运行时框架 是 Apollo 的操作环境它是 ROS（机器人操作系统）的定制版，ROS 实际上是一个在 Apollo RTOS 上运行的软件框架。ROS 在机器人行业有着悠久的历史，目前有 3,000 多个基础库支持应用程序的快速开发，ROS 根据功能将自治系统划分为多个模块，每个模块负责接收、处理和发布自己的消息。由于这些模块相互独立 只能通过运行时框架进行通信，因此调整任何单一模块都很容易。ROS 是应用最广泛的机器人框架，因此它所包含的模块涉及许多最新的研究突破，所有这些功能使 ROS 成为理想的 Apollo 开发与集成框架。 为使 ROS 适应无人驾驶车，Apollo 团队改进了共享内存的功能和性能、去中心化和数据兼容性 共享内存降低了需要访问不同模块时的数据复制需求。 对于一对多传输方案，共享内存支持“一次写入 多次读取”模式。例如 如果你只收到一次点云 你可以同时运行障碍物检测、定位和 GUI 工具。这可以加快通信速度 去中心化 解决了单点故障问题 现成的 ROS 由许多节点组成,每个节点都有对应的功能。例如 一个节点可能负责收集摄像头图像，另一个节点可能负责规划轨迹，而第三个节点可能负责将控制命令发送到 CAN 总线上的车辆，但是所有这些节点都需要由单个 ROS 主节点来控制。如果这个主节点发生故障，整个系统都会失效。 为了避免这个问题，Apollo 将所有节点放在一个公共域中，域中的每个节点都有关于域中其他节点的信息，通过这种去中心化方案，公共域取代了原来的 ROS 主节点，因此消除了单点故障风险。 对于无人驾驶车来说 由于项目本身的规模很大，数据兼容性 至关重要 不同的 ROS 节点通过,名为 ROS 消息的接口语言相互通信。ROS 消息需要使用通用接口语言，使每个节点都可以解读来自其他节点的消息数据。如果消息文件的格式，与节点所期望的格式稍有不同，通信会失败，这可能会导致严重的兼容性问题。例如 当一个接口升级时，数据不兼容通常会导致系统故障。此外 必须一次又一次地转换之前所记录的测试数据， 以适应新的消息格式。 为了解决这个问题，Apollo 团队使用另一种名为 protobuf 的接口语言，来替代原生 ROS 消息。Protobuf 是一种结构化数据序列化方法. 这对开发用于通过电线彼此通信，或用于存储数据的程序非常有用。你可以将新字段添加到消息格式中 而不会破坏后向兼容性，新的二进制文件可以在解析过程中接受旧的消息格式。向 ROS 添加 protobuf 格式有助于 Apollo 的长期发展。 应用程序模块 Apollo 的软件平台具有各种模块，这些模块包括 MAP 引擎、定位、感知、规划、控制、端到端驾驶以及人机接口（或 HMI）。每个模块都有自己的算法库，模块之间的关系非常复杂。后续将在整个课程中对这些模块及其关联方式进行研究 云服务Apollo 云服务包含高精度地图(HD Maps)、仿真环境(Simulation)、数据平台(Data Platform)、安全(Security)、软件升级(OTA)以及被称为 DuerOS 的智能语音系统 在这里 我们将重点介绍仿真和数据平台。 仿真环境平台是 Apollo 开放软件栈的重要工具 该平台允许每个人出于自身需要 来构建仿真环境。该平台还聚合了大量驾驶数据，使开发人员能够检验和验证无人驾驶软件系统。仿真环境使 Apollo 车辆不仅可以查看环境，还可以了解道路情况和场景。 仿真环境平台具有许多功能。首先，仿真环境平台允许开发人员配置不同的驾驶场景，比如障碍物，路线和交通灯状态。执行模式为开发人员提供了一个在多个场景中运转的完整设置。在执行模式中 ，开发人员可以在 Apollo 环境中上传和验证模块。当前的自动评分系统，从几个指标对场景进行评估。其中包括：碰撞检测、交通灯识别、速度限制、障碍物检测和路线逻辑。最后，三维可视化描述了实时路况。在显示无人驾驶车状态的同时，使模块输出可视化。 数据对无人驾驶车来说很重要。无人驾驶数据可能来自模拟场景或道路测试，Apollo 为这些类别提供了各种各样的数据。 仿真场景数据有两个不同的来源：记录场景和虚拟场景。我们可以使用记录的场景，来重放我们在实际道路测试中已经观察到的传感器数据，我们可以借助虚拟场景 使用虚拟编辑器创建新的驾驶场景，这有助于快速检验与验证算法。为了训练像深度学习网络那样的机器学习模型，我们需要带标签的注释数据，其中包括交通信号灯数据，带边界框的障碍物数据，以及语义分割数据。 此外 Apollo 已向公众发布了 ApolloScape 数据集。ApolloScape 涵盖了各种复杂路况，ApolloScape 在单个图像中列入并注释了，多达 162 辆车或 80 名行人。同时 开放数据集使用语义分割对图像进行逐像素标记，这使得 ApolloScape 成为世界上最为复杂又最精确的无人驾驶数据集。]]></content>
      <categories>
        <category>self-driving</category>
      </categories>
      <tags>
        <tag>无人驾驶 Apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习框架（Deep Learning frameworks）-吴恩达 深度学习 course2 3.10笔记]]></title>
    <url>%2FDeepLearning%2F2018-05-21-course2-Week3-10-deep%20learning%20frameworks.html</url>
    <content type="text"><![CDATA[3.10 深度学习框架（Deep Learning frameworks）我认为现在深度学习已经很成熟了，利用一些深度学习框架会更加实用，会使你的工作更加有效，那就让我们来看下有哪些框架。 Caffe / Caffe 2 CNTK DL4J Keras Lasagne mxnet PaddlePaddle TensorFlow Theano Torch 选择框架的标准 便于编程：包括神经网络的开发和迭代、配置产品； 运行速度：特别是训练大型数据集时； 是否真正开放：不仅需要开源，而且需要良好的管理，能够持续开放所有功能。 3.11 TensorFlow有很多很棒的深度学习编程框架，其中一个是TensorFlow Tensorflow 框架内可以直接调用梯度下降算法，极大地降低了编程人员的工作量。例如 Writing and running programs in TensorFlow has the following steps: Create Tensors (variables) that are not yet executed/evaluated. Write operations between those Tensors. Initialize your Tensors. Create a Session. Run the Session. This will run the operations you’d written above. 123456789101112131415161718192021222324252627import numpy as npimport tensorflow as tfcofficients = np.array([[1.],[-20.],[25.]])w = tf.Variable(0,dtype=tf.float32)x = tf.placeholder(tf.float32,[3,1])# cost = tf.add(tf.add(w**2,tf.multiply(- 10.,w)),25)# Tensorflow 重载了加减乘除符号cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]# 改变下面这行代码，可以换用更好的优化算法train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)# 下面的几行是惯用表达式:init = tf.global_variables_initializer()session = tf.Session()#这样就开启了一个TensorFlow session。session.run(init)#来初始化全局变量。print(session.run(w))# with tf.Session() as session:# session.run(init)# print(session.run(w)) for i in range(1000): session.run(train, feed_dict=(x:coefficients))print(session.run(w)) 一旦被称为TensorFlow变量，平方，乘法和加减运算都重载了 with 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭、线程中锁的自动获取和释放等。 TensorFlow中的placeholder是一个你之后会赋值的变量，这种方式便于把训练数据加入损失方程 当你运行训练迭代，用feed_dict来让x=coefficients。如果你在做mini-batch梯度下降，在每次迭代时，你需要插入不同的mini-batch，那么每次迭代，你就用feed_dict来喂入训练集的不同子集，把不同的mini-batch喂入损失函数需要数据的地方。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归一化网络的激活函数（Normalizing activations in a network）-吴恩达 深度学习 course2 3.4~3.7笔记]]></title>
    <url>%2FDeepLearning%2F2018-05-12-course2-Week3-4-Normalizing%20activations%20in%20a%20network.html</url>
    <content type="text"><![CDATA[3.4 归一化网络的激活函数（Normalizing activations in a network）在深度学习兴起后，最重要的一个思想是它的一种算法，叫做Batch归一化。 Batch归一化（Batch Normalization，经常简称为 BN）会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会是你的训练更加容易，甚至是深层网络。 之前，我们对输入特征 X 使用了标准化处理。我们也可以用同样的思路处理隐藏层的激活值 a[l]，以加速 W[l+1]和 b[l+1]的训练。在实践中，经常选择标准化 Z[l]： $$\mu = \frac{1}{m} \sum_i z^{(i)}$$ $$\sigma^2 = \frac{1}{m} \sum_i {(z_i - \mu)}^2$$ $$z_{norm}^{(i)} = \frac{z^{(i)} - \mu}{\sqrt{\sigma^2 + \epsilon}}$$ 其中，m 是单个 mini-batch 所包含的样本个数，ϵ 是为了防止分母为零，通常取 10−8。 这样，我们使得所有的输入 z(i)均值为 0，方差为 1。但我们不想让隐藏层单元总是含有平均值 0 和方差 1，也许隐藏层单元有了不同的分布会更有意义。因此，我们计算 $$\tilde z^{(i)} = \gamma z^{(i)}_{norm} + \beta$$ 其中，γ 和 β 都是模型的学习参数，所以可以用各种梯度下降算法来更新 γ 和 β 的值，如同更新神经网络的权重一样。 通过对 γ 和 β 的合理设置，可以让$$\tilde z^{(i)}$$的均值和方差为任意值。这样，我们对隐藏层的 z^(i)进行标准化处理，用得到的$$\tilde z^{(i)}$$替代 z(i)。 设置 γ 和 β 的原因是，如果各隐藏层的输入均值在靠近 0 的区域，即处于激活函数的线性区域，不利于训练非线性神经网络，从而得到效果较差的模型。因此，需要用 γ 和 β 对标准化后的结果做进一步处理。 3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）对于 L 层神经网络，经过 Batch Normalization 的作用，整体流程如下： 实际上，Batch Normalization 经常使用在 mini-batch 上，这也是其名称的由来。 使用 Batch Normalization 时，因为标准化处理中包含减去均值的一步，因此 b 实际上没有起到作用，其数值效果交由 β 来实现。因此，在 Batch Normalization 中，可以省略 b 或者暂时设置为 0。 在使用梯度下降算法时，分别对 W[l]，β[l]和 γ[l]进行迭代更新。除了传统的梯度下降算法之外，还可以使用之前学过的动量梯度下降、RMSProp 或者 Adam 等优化算法。 3.6 Batch Norm 为什么奏效？（Why does Batch Norm work?）Batch Normalization 效果很好的原因有以下两点： 通过对隐藏层各神经元的输入做类似的标准化处理，提高神经网络训练速度； 可以使前面层的权重变化对后面层造成的影响减小，整体网络更加健壮。 关于第二点，如果实际应用样本和训练样本的数据分布不同（例如，橘猫图片和黑猫图片），我们称发生了“Covariate Shift”。这种情况下，一般要对模型进行重新训练。Batch Normalization 的作用就是减小 Covariate Shift 所带来的影响，让模型变得更加健壮，鲁棒性（Robustness）更强。 即使输入的值改变了，由于 Batch Normalization 的作用，使得均值和方差保持不变（由 γ 和 β 决定），限制了在前层的参数更新对数值分布的影响程度，因此后层的学习变得更容易一些。Batch Normalization 减少了各层 W 和 b 之间的耦合性，让各层更加独立，实现自我训练学习的效果。 另外，Batch Normalization 也起到微弱的正则化（regularization）效果。因为在每个 mini-batch 而非整个数据集上计算均值和方差，只由这一小部分数据估计得出的均值和方差会有一些噪声，因此最终计算出的 z~(i)也有一定噪声。类似于 dropout，这种噪声会使得神经元不会再特别依赖于任何一个输入特征。 因为 Batch Normalization 只有微弱的正则化效果，因此可以和 dropout 一起使用，以获得更强大的正则化效果。通过应用更大的 mini-batch 大小，可以减少噪声，从而减少这种正则化效果。 最后，不要将 Batch Normalization 作为正则化的手段，而是当作加速学习的方式。正则化只是一种非期望的副作用，Batch Normalization 解决的还是反向传播过程中的梯度问题（梯度消失和爆炸）。 3.7 测试时的 Batch Norm（Batch Norm at test time）在训练时， μ 和 σ2是在整个mini-batch上计算出来的.包含了像是64或28或其它一定数量的样本 但在测试时，你可能需要逐一处理样本，方法是根据你的训练集估算和，估算的方式有很多种，理论上你可以在最终的网络中运行整个训练集来得到 μ 和 σ2 但在实际操作中，我们通常运用指数加权平均来追踪在训练过程中你看到的 μ 和 σ2的值。还可以用指数加权平均，有时也叫做流动平均来粗略估算 μ 和 σ2，然后在测试中使用和的值来进行你所需要的隐藏单元值的调整。 对于第 l 层隐藏层，考虑所有 mini-batch 在该隐藏层下的 μ[l]和 σ2[l]，然后用指数加权平均的方式来预测得到当前单个样本的 μ[l]和 σ2[l]。这样就实现了对测试过程单个样本的均值和方差估计。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Softmax 回归（Softmax regression）-吴恩达 深度学习 course2 3.8~3.9笔记]]></title>
    <url>%2FDeepLearning%2F2018-05-16-course2-Week3-8-%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[3.8 Softmax 回归（Softmax regression）目前为止，介绍的分类例子都是二分类问题：神经网络输出层只有一个神经元，表示预测输出 y^是正类的概率 P(y = 1|x)，y &gt; 0.5 则判断为正类，反之判断为负类。 对于多分类问题，用 C 表示种类个数，则神经网络输出层，也就是第 L 层的单元数量 n[L]=C。每个神经元的输出依次对应属于该类的概率，即 P(y=c|x),c=0,1,..,C−1。有一种 Logistic 回归的一般形式，叫做 Softmax 回归，可以处理多分类问题。 对于 Softmax 回归模型的输出层，即第 L 层，有： $$Z^{[L]} = W^{[L]}a^{[L-1]} + b^{[L]}$$ $$a^{[L]}_i = \frac{e^{Z^{[L]}i}}{\sum^C{i=1}e^{Z^{[L]}_i}}$$ 为输出层每个神经元的输出，对应属于该类的概率，满足： $$\sum^C_{i=1}a^{[L]}_i = 1$$简单来说就是用临时变量t将它归一化，使总和为1。一个直观的计算例子如下： 3.9 训练一个 Softmax 分类器（Training a Softmax classifier） 怎样训练带有Softmax输出层的神经网络，具体而言，我们先定义训练神经网络使会用到的损失函数。 $$L(\hat y, y) = -\sum^C_{j=1}y_jlog\hat y_j$$概括来讲，损失函数所做的就是它找到你的训练集中的真实类别，然后试图使该类别相应的概率尽可能地高，如果你熟悉统计学中最大似然估计，这其实就是最大似然估计的一种形式。 这是单个训练样本的损失，整个训练集的损失J又如何呢？ $$J = \frac{1}{m}\sum^m_{i=1}L(\hat y, y)$$因此你要做的就是用梯度下降法，使这里的损失最小化。 最后我们来看一下，在有Softmax输出层时如何实现梯度下降法 多分类的 Softmax 回归模型与二分类的 Logistic 回归模型只有输出层上有一点区别。经过不太一样的推导过程，仍有 $$dZ^{[L]} = A^{[L]} - Y$$反向传播过程的其他步骤也和 Logistic 回归的一致。 详细可参考：softmax 回归]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[调试处理（Tuning process）-吴恩达 深度学习 course2 3.1~3.3笔记]]></title>
    <url>%2FDeepLearning%2F2018-05-08-course2-Week3-1-Tuning%20process.html</url>
    <content type="text"><![CDATA[对于超参数而言，如何找到一套好的设定呢？本课中，我将和你分享一些指导原则，一些关于如何系统地组织超参调试过程的技巧。 调试处理（Tuning process）参数的重要程度排序关于训练深度最难的事情之一是你要处理的参数的数量，从学习速率 α 到Momentum（动量梯度下降法）的参数 β 。如果使用Momentum或Adam优化算法的参数 β1，β2和 ε，也许你还得选择层数，也许你还得选择不同层中隐藏单元的数量，也许你还想使用学习率衰减。所以，你使用的不是单一的学习率α。接着，当然你可能还需要选择mini-batch的大小。 结果证实一些超参数比其它的更为重要。 最重要 学习速率 α； 其次重要 β：动量衰减参数，常设置为 0.9； #hidden units：各隐藏层神经元个数； mini-batch 的大小； 重要性排第三位 β1，β2，ϵ：Adam 优化算法的超参数，常设为 0.9、0.999、10−8； #layers：神经网络层数; decay_rate：学习衰减率； ![hyperparameters](https://raw.githubusercontent.com/songapore/For-PicGo/master/img/hyperparameters.png) 希望你粗略了解到哪些超参数较为重要，α无疑是最重要的，接下来是我用橙色圈住的那些，然后是我用紫色圈住的那些，但这不是严格且快速的标准，我认为，其它深度学习的研究者可能会很不同意我的观点或有着不同的直觉。 调参技巧随机选择点 现在，如果你尝试调整一些超参数，该如何选择调试值呢？在早一代的机器学习算法中，如果你有两个超参数，这里我会称之为超参1，超参2，常见的做法是在网格中取样点，像这样，然后系统的研究这些数值。这里我放置的是5×5的网格，实践证明，网格可以是5×5，也可多可少，但对于这个例子，你可以尝试这所有的25个点，然后选择哪个参数效果最好。当参数的数量相对较少时，这个方法很实用。 在深度学习领域，我推荐你采用随机选择点，你可以选择同等数量的点，25个点，接着，用这些随机取的点试验超参数的效果。之所以这么做是因为，对于你要解决的问题而言，你很难提前知道哪个超参数最重要，正如你之前看到的，一些超参数的确要比其它的更重要。 举个例子，假设超参数1是α（学习速率），取一个极端的例子，假设超参数2是Adam算法中，分母中的ε。在这种情况下，α的取值很重要，而ε取值则无关紧要。如果你在网格中取点，接着，你试验了αα的5个取值，那你会发现，无论ε取何值，结果基本上都是一样的。所以，你知道共有25种模型，但进行试验的α值只有5个，我认为这是很重要的。 对比而言，如果你随机取值，你会试验25个独立的，似乎你更有可能发现效果做好的那个。 实践中，哪个是最重要的超参数，对于你的具体应用而言，随机取值而不是网格取值表明，你探究了更多重要超参数的潜在值，无论结果是什么。 由粗糙到精细的策略当你给超参数取值时，另一个惯例是采用 由粗糙到精细的策略 :聚焦效果不错的点组成的小区域，在其中更密集地取值，以此类推 比如在二维的那个例子中，你进行了取值，也许你会发现效果最好的某个点，也许这个点周围的其他一些点效果也很好，那在接下来要做的是放大这块小区域（小蓝色方框内），然后在其中更密集得取值或随机取值，聚集更多的资源，在这个蓝色的方格中搜索，如果你怀疑这些超参数在这个区域的最优结果，那在整个的方格中进行粗略搜索后，你会知道接下来应该聚焦到更小的方格中。在更小的方格中，你可以更密集得取点。所以这种从粗到细的搜索也经常使用。 通过试验超参数的不同取值，你可以选择对训练集目标而言的最优值，或对于开发集而言的最优值，或在超参搜索过程中你最想优化的东西。 我希望，这能给你提供一种方法去系统地组织超参数搜索过程。另一个关键点是随机取值和精确搜索，考虑使用由粗糙到精细的搜索过程。 3.2为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）在上一课中，你已经看到了在超参数范围中，随机取值可以提升你的搜索效率。但随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数。 对于学习率 α，用对数标尺而非线性轴的方式搜索超参数更加合理：0.0001、0.001、0.01、0.1 等，然后在这些刻度之间再随机均匀取值； 对于 β，取 0.9 就相当于在 10 个值中计算平均值，而取 0.999 就相当于在 1000 个值中计算平均值。可以考虑给 1-β 取值，这样就和取学习率类似了。 上述操作的原因是当 β 接近 1 时，即使 β 只有微小的改变，所得结果的灵敏度会有较大的变化。例如，β 从 0.9 增加到 0.9005 对结果（1/(1-β)）几乎没有影响，而 β 从 0.999 到 0.9995 对结果的影响巨大（从 1000 个值中计算平均值变为 2000 个值中计算平均值）。 3.3 超参数训练的实践：Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar） 深度学习如今已经应用到许多不同的领域。不同的应用出现相互交融的现象，某个应用领域的超参数设定有可能通用于另一领域。不同应用领域的人也应该更多地阅读其他研究领域的 paper，跨领域地寻找灵感； 考虑到数据的变化或者服务器的变更等因素，建议每隔几个月至少一次，重新测试或评估超参数，来获得实时的最佳模型； 根据你所拥有的计算资源来决定你训练模型的方式： Panda（熊猫方式）：在在线广告设置或者在计算机视觉应用领域有大量的数据，但受计算能力所限，同时试验大量模型比较困难。可以采用这种方式：试验一个或一小批模型，初始化，试着让其工作运转，观察它的表现，不断调整参数； Caviar（鱼子酱方式）：拥有足够的计算机去平行试验很多模型，尝试很多不同的超参数，选取效果最好的模型；]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[局部最优的问题(The problem of local optima)-吴恩达 深度学习 course2 2.10笔记]]></title>
    <url>%2FDeepLearning%2F2018-05-07-course2-Week2-10-The%20problem%20of%20local%20optima.html</url>
    <content type="text"><![CDATA[在深度学习研究早期，人们总是担心优化算法会困在极差的局部最优，不过随着深度学习理论不断发展，我们对局部最优的理解也发生了改变。我向你展示一下现在我们怎么看待局部最优以及深度学习中的优化问题。 这是曾经人们在想到局部最优时脑海里会出现的图，也许你想优化一些参数，我们把它们称之为W1和W2，平面的高度就是损失函数。在图中似乎各处都分布着局部最优。梯度下降法或者某个算法可能困在一个局部最优中，而不会抵达全局最优。如果你要作图计算一个数字，比如说这两个维度，就容易出现有多个不同局部最优的图，而这些低维的图曾经影响了我们的理解，但是这些理解并不正确。 事实上，如果你要创建一个神经网络，通常梯度为零的点并不是这个图中的局部最优点，实际上成本函数的零梯度点，通常是鞍点。 所以我们从深度学习历史中学到的一课就是，我们对低维度空间的大部分直觉，比如你可以画出上面的图，并不能应用到高维度空间中。适用于其它算法，因为如果你有2万个参数，那么函数有2万个维度向量，你更可能遇到鞍点，而不是局部最优点。 鞍点（saddle）是函数上的导数为零，但不是轴上局部极值的点。当我们建立一个神经网络时，通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。因为在一个具有高维度空间的成本函数中，如果梯度为 0，那么在每个方向，成本函数或是凸函数，或是凹函数。而所有维度均需要是凹函数的概率极小，因此在低维度的局部最优点的情况并不适用于高维度。 结论： 在训练较大的神经网络、存在大量参数，并且成本函数被定义在较高的维度空间时，困在极差的局部最优中是不大可能的； 鞍点附近的平稳段会使得学习非常缓慢，而这也是动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习率衰减(Learning rate decay)-吴恩达 深度学习 course2 2.9笔记]]></title>
    <url>%2FDeepLearning%2F2018-05-06-course2-Week2-9-Learning%20rate%20decay.html</url>
    <content type="text"><![CDATA[加快学习算法的一个办法就是随时间慢慢减少学习率，我们将之称为学习率衰减，我们来看看如何做到。 为什么要计算学习率衰减假设你要使用mini-batch梯度下降法，mini-batch数量不大，大概64或者128个样本，在迭代过程中会有噪音（蓝色线），下降朝向这里的最小值，但是不会精确地收敛，所以你的算法最后在附近摆动，并不会真正收敛，因为你用的α是固定值，不同的mini-batch中有噪音。 但要慢慢减少学习率α的话，在初期的时候，学习率α还较大，你的学习还是相对较快，但随着α变小，你的步伐也会变慢变小，所以最后你的曲线（绿色线）会在最小值附近的一小块区域里摆动，而不是在训练过程中，大幅度在最小值附近摆动。 所以慢慢减少的本质在于，在学习初期，你能承受较大的步伐，但当开始收敛的时候，小一些的学习率能让你步伐小一些。 最常用的学习率衰减方法：$$\alpha = \frac{1}{1 + decay_rate epoch_num} \alpha_0$$其中，decay_rate为衰减率（超参数），epoch_num为将所有的训练样本完整过一遍的次数。注意这个衰减率是另一个你需要调整的超参数 要理解，作为代数函数，根据上述公式，你的学习率呈递减趋势。如果你想用学习率衰减，要做的是要去尝试不同的值，找到合适的值，除了这个学习率衰减的公式，人们还会用其它的公式。 其它的学习率衰减方法 指数衰减： $$\alpha = 0.95^{epoch_num} * \alpha_0$$ 其他： $$\alpha = \frac{k}{\sqrt{epoch_num}} * \alpha_0$$ 离散下降]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Adam 优化算法(Adam optimization algorithm)-吴恩达 深度学习 course2 2.8笔记]]></title>
    <url>%2FDeepLearning%2F2018-05-02-course2-Week2-8-Adam%20optimization%20algorithm.html</url>
    <content type="text"><![CDATA[在深度学习的历史上，包括许多知名研究者在内，提出了优化算法，并很好地解决了一些问题，但随后这些优化算法被指出并不能一般化，并不适用于多种神经网络。 RMSprop以及Adam优化算法，就是少有的经受住人们考验的两种算法，已被证明适用于不同的深度学习结构，这个算法我会毫不犹豫地推荐给你，因为很多人都试过，并且用它很好地解决了许多问题。 实现Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）基本上就是将 Momentum 和 RMSProp 算法结合在一起，通常有超越二者单独时的效果。那么来看看如何使用Adam算法 使用Adam算法，首先你要初始化： $$v_{dW} = 0, s_{dW} = 0, v_{db} = 0, s_{db} = 0$$ 用每一个 mini-batch 计算 dW、db，第 t 次迭代时 $$v_{dW} = \beta_1 v_{dW} + (1 - \beta_1) dW$$ $$v_{db} = \beta_1 v_{db} + (1 - \beta_1) db$$ $$s_{dW} = \beta_2 s_{dW} + (1 - \beta_2) {(dW)}^2$$ $$s_{db} = \beta_2 s_{db} + (1 - \beta_2) {(db)}^2$$ 一般使用 Adam 算法时需要计算偏差修正： $$v^{corrected}{dW} = \frac{v{dW}}{1-{\beta_1}^t}$$ $$v^{corrected}{db} = \frac{v{db}}{1-{\beta_1}^t}$$ $$s^{corrected}{dW} = \frac{s{dW}}{1-{\beta_2}^t}$$ $$s^{corrected}{db} = \frac{s{db}}{1-{\beta_2}^t}$$ 所以，更新 W、b 时有： $$W := W - \alpha \frac{v^{corrected}{dW}}{\sqrt{s^{corrected}{dW}} + \epsilon}$$ $$b := b - \alpha \frac{v^{corrected}{db}}{\sqrt{s^{corrected}{db}} + \epsilon}$$ （可以看到 Andrew 在这里 ϵ 没有写到平方根里去，和他在 RMSProp 中写的不太一样。考虑到 ϵ 所起的作用，我感觉影响不大） 超参数选择 Adam 优化算法有很多的超参数，其中 学习率 α：需要尝试一系列的值，来寻找比较合适的； β1：常用的缺省值为 0.9； β2：Adam 算法的作者建议为 0.999； ϵ：不重要，不会影响算法表现，Adam 算法的作者建议为 10−8； β1、β2、ϵ 通常不需要调试。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RMSprop算法-吴恩达 深度学习 course2 2.7笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-30-course2-Week2-7-RMSProp.html</url>
    <content type="text"><![CDATA[你们知道了动量（Momentum）可以加快梯度下降，还有一个叫做RMSprop的算法，全称是root mean square prop算法，它也可以加速梯度下降，我们来看看它是如何运作的。 原理RMSProp算法是在对梯度进行指数加权平均的基础上，引入平方和平方根。 如果你执行梯度下降，虽然横轴方向正在推进，但纵轴方向会有大幅度摆动，为了分析这个例子，假设纵轴代表参数b，横轴代表参数W. 所以，你想减缓 纵轴方向的学习，同时加快 横轴方向的学习，RMSprop算法可以实现这一点 我们来理解一下其原理。我们希望W学习速度快，而在垂直方向，也就是例子中的b方向，我们希望减缓纵轴上的摆动，所以有了和S_dw, S_db. 我们希望S_dw会相对较小，所以我们要除以一个较小的数，而希望S_db又较大，所以这里我们要除以较大的数字，这样就可以减缓纵轴上的变化。 因为函数的倾斜程度，在纵轴上，也就是b方向上要大于在横轴上，也就是W方向上。db的平方较大，所以S_db也会较大，而相比之下，dw会小一些，亦或平方会小一些，因此S_dw会小一些，结果就是纵轴上的更新要被一个较大的数相除，就能消除摆动，而水平方向的更新则被较小的数相除。 RMSprop的影响就是你的更新最后会变成这样（绿色线），纵轴方向上摆动较小，而横轴方向继续推进。还有个影响就是，你可以用一个更大学习率，然后加快学习，而无须在纵轴上垂直方向偏离。 实现$$s_{dw} = \beta s_{dw} + (1 - \beta)(dw)^2$$ $$s_{db} = \beta s_{db} + (1 - \beta)(db)^2$$ $$w := w - \alpha \frac{dw}{\sqrt{s_{dw} + \epsilon}}$$ $$b := b - \alpha \frac{db}{\sqrt{s_{db} + \epsilon}}$$ 如果的平方根趋近于0怎么办？得到的答案就非常大，为了确保数值稳定，在实际中，你要在分母上加上一个很小很小的ϵ，是多少没关系，10^-8是个不错的选择，这只是保证数值能稳定一些。 题外话所以RMSprop跟Momentum有很相似的一点，可以消除梯度下降中的摆动，包括mini-batch梯度下降，并允许你使用一个更大的学习率，从而加快你的算法学习速度。 所以你学会了如何运用RMSprop，这是给学习算法加速的另一方法。关于RMSprop的一个有趣的事是，它首次提出并不是在学术研究论文中，而是在多年前Jeff Hinton在Coursera的课程上。我想Coursera并不是故意打算成为一个传播新兴的学术研究的平台，但是却达到了意想不到的效果。就是从Coursera课程开始，RMSprop开始被人们广为熟知，并且发展迅猛。 我们讲过了Momentum，我们讲了RMSprop，如果二者结合起来，你会得到一个更好的优化算法，在下个视频中我们再好好讲一讲为什么。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动量梯度下降法（Gradient descent with Momentum）-吴恩达 深度学习 course2 2.6笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-29-course2-Week2-6-Gradient%20descent%20with%20Momentum.html</url>
    <content type="text"><![CDATA[定义及实现过程动量梯度下降（Gradient Descent with Momentum）是计算梯度的指数加权平均数，并利用该值来更新参数值。 动量梯度下降法的运行速度几乎总是快于标准的梯度下降算法。具体过程为： for l = 1, .. , L： $$v_{dW^{[l]}} = \beta v_{dW^{[l]}} + (1 - \beta) dW^{[l]}$$ $$v_{db^{[l]}} = \beta v_{db^{[l]}} + (1 - \beta) db^{[l]}$$ $$W^{[l]} := W^{[l]} - \alpha v_{dW^{[l]}}$$ $$b^{[l]} := b^{[l]} - \alpha v_{db^{[l]}}$$ 其中，将动量衰减参数 β 设置为 0.9 是超参数的一个常见且效果不错的选择。当 β 被设置为 0 时，显然就成了 batch 梯度下降法。 进行一般的梯度下降将会得到图中的蓝色曲线，由于存在上下波动，减缓了梯度下降的速度，因此只能使用一个较小的学习率进行迭代。如果用较大的学习率，结果可能会像紫色曲线一样偏离函数的范围。 而使用动量梯度下降时，通过累加过去的梯度值来减少抵达最小值路径上的波动，加速了收敛，因此在横轴方向下降得更快，从而得到图中红色的曲线。 当前后梯度方向一致时，动量梯度下降能够加速学习；而前后梯度方向不一致时，动量梯度下降能够抑制震荡。 另外，在 10 次迭代之后，移动平均已经不再是一个具有偏差的预测。因此实际在使用梯度下降法或者动量梯度下降法时，不会同时进行偏差修正。 动量梯度下降法的形象解释将成本函数想象为一个碗状，从顶部开始运动的小球向下滚，其中 dw，db 想象成球的加速度；而 vdw、vdb 相当于速度。 小球在向下滚动的过程中，因为加速度的存在速度会变快，但是由于 β 的存在，其值小于 1，可以认为是摩擦力，所以球不会无限加速下去。 最后要说一点，如果你查阅了动量梯度下降法相关资料，你经常会看到 1-β 被删除了，即 $$v_{dW^{[l]}} = \beta v_{dW^{[l]}} +dW^{[l]}$$ 所以V_dw缩小了1-β倍,所以你要用梯度下降最新值的话，a也要相应变化。实际上这2种方法效果都不错，只会影响到学习率a的最佳值。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[指数加权平均（Exponentially Weight Average）-吴恩达 深度学习 course2 2.3~2.5笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-28-course2-Week2-3-%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87%E6%95%B0%EF%BC%88Exponentially%20weighted%20averages).html</url>
    <content type="text"><![CDATA[计算公式 指数加权平均（Exponentially Weight Average）是一种常用的序列数据处理方式，计算公式为： $$S_t =\begin{cases}Y_1, &amp;t = 1 \\beta S_{t-1} + (1-\beta)Y_t, &amp;t &gt; 1\end{cases}$$ 其中 Yt 为 t 下的实际值，St 为 t 下加权平均后的值，β 为权重值。 给定一个时间序列，例如伦敦一年每天的气温值，图中蓝色的点代表真实数据。对于一个即时的气温值，取权重值 β 为 0.9，根据求得的值可以得到图中的红色曲线，它反映了气温变化的大致趋势。 当取权重值 β=0.98 时，可以得到图中更为平滑的绿色曲线。而当取权重值 β=0.5 时，得到图中噪点更多的黄色曲线 。β 越大相当于求取平均利用的天数越多，曲线自然就会越平滑而且越滞后。 理解指数加权平均当 β 为 0.9 时， $$v_{100} = 0.9v_{99} + 0.1 \theta_{100}$$ $$v_{99} = 0.9v_{98} + 0.1 \theta_{99}$$ $$v_{98} = 0.9v_{97} + 0.1 \theta_{98}$$ … $$v_{100} = 0.1 \theta_{100} + 0.1 0.9 \theta_{99} + 0.1 {(0.9)}^2 \theta_{98} + …$$ 其中 θi 指第 i 天的实际数据。所有 θ 前面的系数（不包括 0.1）相加起来为 1 或者接近于 1，这些系数被称作偏差修正（Bias Correction）。 根据函数极限的定理： $${\lim_{\beta\to 0}}(1 - \beta)^{\frac{1}{\beta}} = \frac{1}{e} \approx 0.368$$ 当 β 为 0.9 时，可以当作把过去 10 天的气温指数加权平均作为当日的气温，因为 10 天后权重已经下降到了当天的 1/3 左右。同理，当 β 为 0.98 时，可以把过去 50 天的气温指数加权平均作为当日的气温。 因此，在计算当前时刻的平均值时，只需要前一天的平均值和当前时刻的值。 $$v_t = \beta v_{t-1} + (1 - \beta)\theta_t$$ 考虑到代码，只需要不断更新 v 即可： $$v := \beta v + (1 - \beta)\theta_t$$ 指数平均加权并不是最精准的计算平均数的方法，你可以直接计算过去 10 天或 50 天的平均值来得到更好的估计，但缺点是保存数据需要占用更多内存，执行更加复杂，计算成本更加高昂。 指数加权平均数公式的好处之一在于它只需要一行代码，且占用极少内存，因此 效率极高，且节省成本。 指数加权平均的偏差修正我们通常有 $$v_0 = 0$$ $$v_1 = 0.98v_0 + 0.02\theta_1$$ 因此，v1 仅为第一个数据的 0.02（或者说 1-β），显然不准确。往后递推同理。 因此，我们修改公式为 $$v_t = \frac{\beta v_{t-1} + (1 - \beta)\theta_t}{1-\beta^t}$$ 随着 t 的增大，β 的 t 次方趋近于 0。因此当 t 很大的时候，偏差修正几乎没有作用，但是在前期学习可以帮助更好的预测数据。在实际过程中，一般会忽略前期偏差的影响。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mini-batch 梯度下降（Mini-batch gradient descent）-吴恩达 深度学习 course2 2.1~2.2笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-27-course2-Week2-1-Mini-batch%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.html</url>
    <content type="text"><![CDATA[Mini-batch 梯度下降（Mini-batch gradient descent）作用机器学习的应用是一个高度依赖经验的过程，伴随着大量迭代的过程，你需要训练诸多模型，才能找到合适的那一个，而优化算法能够帮助你快速训练模型。 深度学习难以在大数据领域发挥最大效果的一个原因是，在巨大的数据集基础上进行训练速度很慢。而优化算法能够帮助快速训练模型，大大提高效率。 定义 batch 梯度下降法（批梯度下降法，我们之前一直使用的梯度下降法）是最常用的梯度下降形式，即同时处理整个训练集。其在更新参数时使用所有的样本来进行更新 但是如果每次处理训练数据的一部分即进行梯度下降法，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为 mini-batch。 mini-batch梯度下降法每次同时处理单个的 mini-batch，其他与 batch 梯度下降法一致。 工作原理那么究竟mini-batch梯度下降法的原理是什么？在训练集上运行mini-batch梯度下降法，你运行for t=1……5000，因为我们有5000个各有1000个样本的组，在for循环里你要做得基本就是对 X^{t}和Y^{t} 执行一步梯度下降法。假设你有一个拥有1000个样本的训练集，而且假设你已经很熟悉一次性处理完的方法，你要用向量化去几乎同时处理1000个样本。 你也会注意到，我们做的一切似曾相识，其实跟之前我们执行梯度下降法如出一辙，除了你现在的对象不是X，Y，而是 X^{t} 和 Y^{t} 这是使用mini-batch梯度下降法训练样本的一步，我写下的代码也可被称为进行“一代”（1 epoch）的训练。一代这个词意味着只是一次遍历了训练集。 使用batch梯度下降法，一次遍历训练集只能让你做一个梯度下降，使用mini-batch梯度下降法，一次遍历训练集，能让你做5000个梯度下降。当然正常来说你想要多次遍历训练集，还需要为另一个while循环设置另一个for循环。所以你可以一直处理遍历训练集，直到最后你能收敛到一个合适的精度。 如果你有一个丢失的训练集，mini-batch梯度下降法比batch梯度下降法运行地更快，所以几乎每个研习深度学习的人在训练巨大的数据集时都会用到，下一课中，我们将进一步深度讨论mini-batch梯度下降法，你也会因此更好地理解它的作用和原理。 理解mini-batch梯度下降法我们将进一步学习如何执行梯度下降法，更好地理解其作用和原理。 原理Mini-Batch 梯度下降法（小批量梯度下降法）每次同时处理单个的 mini-batch，其他内容与 batch 梯度下降法一致。 使用 batch 梯度下降法，对整个训练集的一次遍历只能做一个梯度下降；而使用 Mini-Batch 梯度下降法，对整个训练集的一次遍历（称为一个 epoch）能做 mini-batch 个数个梯度下降。之后，可以一直遍历训练集，直到最后收敛到一个合适的精度。 batch 梯度下降法和 Mini-batch 梯度下降法代价函数的变化趋势如下： 使用batch梯度下降法时，每次迭代你都需要历遍整个训练集，可以预期每次迭代成本都会下降，所以成本函数J是迭代次数的一个函数，它应该会随着每次迭代而减少，如果在某次迭代中J增加了，那肯定出了问题，也许你的学习率太大。 使用mini-batch梯度下降法，如果你作出成本函数在整个过程中的图，发现并不是每次迭代都是下降的，特别是在每次迭代中，你要处理的是 X^{t} 和 Y^{t}，如果要作出成本函数 J^{t} 的图，而 J^{t} 只和 X^{t} 和 Y^{t} 有关，也就是每次迭代下你都在训练不同的样本集或者说训练不同的mini-batch，如果你要作出成本函数的图，你很可能会看到这样的结果，走向朝下，但有更多的噪声，所以如果你作出的J^{t}图，因为在训练mini-batch梯度下降法时，会经过多代，你可能会看到这样的曲线。没有每次迭代都下降是不要紧的，但走势应该向下。 batch 的不同大小（size）带来的影响 mini-batch 的大小为 1，即是随机梯度下降法（stochastic gradient descent），每个样本都是独立的 mini-batch； mini-batch 的大小为 m（数据集大小），即是 batch 梯度下降法； batch 梯度下降法： 对所有 m 个训练样本执行一次梯度下降，每一次迭代时间较长，训练过程慢； 相对噪声低一些，幅度也大一些； 成本函数总是向减小的方向下降。 随机梯度下降法： 对每一个训练样本执行一次梯度下降，训练速度快，但丢失了向量化带来的计算加速； 有很多噪声，减小学习率可以适当； 成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。mini-batch 大小的选择如果mini-batch大小既不是1也不是，应该取中间值，那应该怎么选择呢？其实是有指导原则的。 首先，如果训练集较小，直接使用batch梯度下降法，样本集较小就没必要使用mini-batch梯度下降法，你可以快速处理整个训练集，所以使用batch梯度下降法也很好，这里的少是说 小于2000个样本， 这样比较适合使用batch梯度下降法。 不然，样本数目较大的话，一般的mini-batch大小为64到512， 考虑到电脑内存设置和使用的方式，如果mini-batch大小是2的n次方， 代码会运行地快一些，64就是2的6次方，以此类推，128是2的7次方，256是2的8次方，512是2的9次方。所以我经常把mini-batch大小设成2的次方。在上一个视频里，我的mini-batch大小设为了1000，建议你可以试一下1024，也就是2的10次方。也有mini-batch的大小为1024，不过比较少见，64到512的mini-batch比较常见。 最后需要注意的是在你的mini-batch中，要确保和要符合CPU/GPU内存，取决于你的应用方向以及训练集的大小。如果你处理的mini-batch和CPU/GPU内存不相符，不管你用什么方法处理数据，你会注意到算法的表现急转直下变得惨不忍睹，所以我希望你对一般人们使用的mini-batch大小有一个直观了解。事实上mini-batch大小是另一个重要的变量，你需要做一个快速尝试，才能找到能够最有效地减少成本函数的那个，我一般会尝试几个不同的值，几个不同的2次方，然后看能否找到一个让梯度下降优化算法最高效的大小。希望这些能够指导你如何开始找到这一数值。 总结起来， 如果训练样本的大小比较小，如 m ⩽ 2000 时，选择 batch 梯度下降法； 如果训练样本的大小比较大，选择 Mini-Batch 梯度下降法。为了和计算机的信息存储方式相适应，代码在 mini-batch 大小为 2 的幂次时运行要快一些。典型的大小为 26、27、…、29； mini-batch 的大小要符合 CPU/GPU 内存。 mini-batch 的大小也是一个重要的超变量，需要根据经验快速尝试，找到能够最有效地减少成本函数的值。 获得 mini-batch 的步骤 将数据集打乱； 按照既定的大小分割数据集；其中打乱数据集的代码： 1234m = X.shape[1]permutation = list(np.random.permutation(m))shuffled_X = X[:, permutation]shuffled_Y = Y[:, permutation].reshape((1,m)) 符号表示约定 使用上角小括号 i 表示训练集里的值，x^(i) 是第 i 个训练样本； 使用上角中括号 l 表示神经网络的层数，z^[l] 表示神经网络中第 l 层的 z 值； 现在引入大括号 t 来代表不同的 mini-batch，因此有 X^{t} 、Y^{t}]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶都在哪些场景实现了落地]]></title>
    <url>%2Fself-driving%2F2018-04-20-self-driving-application.html</url>
    <content type="text"><![CDATA[自动驾驶正在你意想不到的各个领域快速落地，并开始服务大众。下面，就一起来盘点一下无人驾驶都在哪些场景实现了落地 1.无人快递车无人快递车，这可能是最早为你服务的无人车。电商与快递市场的急速增长，快递小哥即使风餐露宿、日以继夜也负担不起日益增长的单量，无人物流车正是为了减轻他们负担而诞生。比如， 阿里菜鸟ET物流实验室无人配送小车系列 京东X事业部智能配送车 智行者蜗必达-无人配送物流车 真机智能&amp;苏宁物流无人物流车 迦智科技园区无人配送车等等2.无人扫地&amp;作业车无人扫地车，为日晒雨淋环卫工人们找个好帮手。环卫 工人们总是默默无闻地把一个城市最脏最累的事情完成。无人扫地车就是为了减轻他们的负担而发明，它不但可以日夜工作，还无惧风雨和烈日，在恶劣天气条件下作业能避免环卫工人受到伤害。目前，各地无人扫地车已在开始运行，并有效完成清扫任务，如 autowire.ai (仙途智能) 6米长的大型清洁车，已在上海松江启迪漕河泾（中山）科技园内试运行作业 智行者“蜗Ω”系列-无人扫路机已在北京的公园内运行作业。3.无人驾驶园区观光&amp;摆渡车如果你想找一辆能坐的无人车，那么无人观光车和无人摆渡车就是不错的选择。这类低速无人驾驶载人车，是目前在落地运营最快的载人无人驾驶项目。比如说 驭势科技的“机场摆渡车” 天隼“旋风智能车” 清智科技无人观光车等等，你可以在体验人工智能高科技的同时还能欣赏风景4.自动驾驶公交车自动驾驶公交车，这可能是未来无人驾驶时代全面到了之时，你使用频率最高的无人驾驶车辆。 去年“刷屏”的深圳智能驾驶公交车–阿尔法巴 李院士主导的北京园博园自动驾驶公交车 青飞智能的G200无人小巴车等等5.无人驾驶乘用车当然，你楼下车库那辆车，也正在变成无人驾驶车辆！ 提到无人驾驶大家最先期待可能还不是上面所提到的“工具车”，而是每天都在开的乘用车，目前使用乘用车做的自动驾驶方案大多为高速场景无人驾驶方案，车辆由小轿车、SUV、甚至房车改装而成。 roadstar.ai 、 图森未来、 环宇智行、 奇瑞、 智尊保等企业，都在快速推动无人驾驶高速场景落地。6.无人大卡车大卡车，无人驾驶也有一颗硬汉的心。在霸气的体量和造型之下，大卡车几乎包揽了全世界所有海港集装箱的陆上运输，在国际贸易中的至关重要，然而由于运输成本，道路通畅性问题，大卡车大多选择在凌晨0点~3点上路，非常不利于驾驶员身体健康，而无人驾驶大卡车就不存在健康问题，更适合晚上作业。比如 图森未来 就是一家无人驾驶货运卡车方案商，图森在中美两国有着先进的无人驾驶大卡车方案正在快速落地。]]></content>
      <categories>
        <category>self-driving</category>
      </categories>
      <tags>
        <tag>无人驾驶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度检验应用的注意事项（Gradient Checking Implementation Notes）-吴恩达 深度学习 course2 1.14笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-19-course2-Week1-14-%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C%E5%BA%94%E7%94%A8%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%EF%BC%88Gradient%20Checking%20Implementation%20Notes%EF%BC%89.html</url>
    <content type="text"><![CDATA[在神经网络实施梯度检验的实用技巧和注意事项。 首先，不要在训练中使用梯度检验，它只用于调试。 我的意思是，计算所有i值的dθapprox[i]是一个非常漫长的计算过程，为了实施梯度下降，你必须使用和 backprop来计算，并使用backprop来计算导数，只要调试的时候，你才会计算它，来确认数值是否接近。完成后，你会关闭梯度检验，梯度检验的每一个迭代过程都不执行它，因为它太慢了。 第二点，如果算法的梯度检验失败，要检查所有项，检查每一项，并试着找出bug。 也就是说，如果与dθ[i]的值相差很大，我们要做的就是查找不同的i值，看看是哪个导致dθapprox[i]与dθ[i]的值相差这么多。 第三点，在实施梯度检验时，当成本函数包含正则项时，也需要带上正则项进行检验； 第四点，梯度检验不能与dropout同时使用。 因为每次迭代过程中，dropout会随机消除隐藏层单元的不同子集，难以计算dropout在梯度下降上的代价函数。因此dropout可作为优化代价函数的一种方法，但是代价函数J被定义为对所有指数极大的节点子集求和。而在任何迭代过程中，这些节点都有可能被消除，所以很难计算代价函数。你只是对成本函数做抽样，用dropout，每次随机消除不同的子集，所以很难用梯度检验来双重检验dropout的计算，所以我一般不同时使用梯度检验和dropout。如果你想这样做，可以把dropout中的keepprob设置为1.0，然后打开dropout，并寄希望于dropout的实施是正确的，你还可以做点别的，比如修改节点丢失模式确定梯度检验是正确的。实际上，我一般不这么做，我建议关闭dropout，用梯度检验进行双重检查，在没有dropout的情况下，你的算法至少是正确的，然后打开dropout。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度检验（Gradient checking）-吴恩达 深度学习 course2 1.13笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-19-course2-Week1-13-%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C%EF%BC%88Gradient%20checking%EF%BC%89.html</url>
    <content type="text"><![CDATA[梯度检验帮我们节省了很多时间，也多次帮我发现backprop实施过程中的bug，接下来，我们看看如何利用它来调试或检验backprop的实施是否正确。 连接参数 将 W[1]，b[1]，…，W[L]，b[L]全部连接出来，成为一个巨型向量 θ。这样， 1J(W[1],b[1],...,W[L]，b[L])=J(θ) 同时，对 dW[1]，db[1]，…，dW[L]，db[L]执行同样的操作得到巨型向量 dθ，它和 θ 有同样的维度。 进行梯度检验 现在的问题是dθ 和代价函数J的梯度或坡度有什么关系？ 首先，我们要清楚 J 是超参数 θ 的一个函数。 使用双边误差，也就是 $$d\theta_{approx}[i] ＝ \frac{J(\theta_1, \theta_2, …, \theta_i+\varepsilon, …) - J(\theta_1, \theta_2, …, \theta_i-\varepsilon, …)}{2\varepsilon}$$ 具体来说，如何定义两个向量是否真的接近彼此？我一般做下列运算，计算这两个向量的距离 $$\frac{||d\theta_{approx} - d\theta||2}{||d\theta{approx}||_2+||d\theta||_2}$$ 注意这里没有平方，它是误差平方之和，然后求平方根，得到欧式距离，然后用向量长度归一化，使用向量长度的欧几里得范数。分母只是用于预防这些向量太小或太大，分母使得这个方程式变成比率 如果左边这个方程式结果是10^-3 ,我就会担心是否存在bug，计算结果应该比10^-3小很多，如果比大很多，我就会很担心，担心是否存在bug。这时应该仔细检查所有项，看是否有一个具体的值，使得与dθ[i]大不相同，并用它来追踪一些求导计算是否正确，经过一些调试，最终结果会是这种非常小的值（10^-7），那么，你的实施可能是正确的。 在实施神经网络时，我经常需要执行foreprop和backprop，然后我可能发现这个梯度检验有一个相对较大的值，我会怀疑存在bug，然后开始调试，调试，调试，调试一段时间后，我得到一个很小的梯度检验值，现在我可以很自信的说，神经网络实施是正确的。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度的数值逼近（Numerical approximation of gradients）-吴恩达 深度学习 course2 1.12笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-19-course2-Week1-12-%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%95%B0%E5%80%BC%E9%80%BC%E8%BF%91%EF%BC%88Numerical%20approximation%20of%20gradients%EF%BC%89.html</url>
    <content type="text"><![CDATA[在实施backprop时，有一个测试叫做梯度检验，它的作用是确保backprop正确实施。因为有时候，你虽然写下了这些方程式，却不能100%确定，执行backprop的所有细节都是正确的。为了逐渐实现梯度检验，我们首先说说如何计算梯度的数值逼近 当 ε 越小时，结果越接近真实的导数，也就是梯度值。 我们可以使用这个方法来检验反向传播是否得以正确实施，如果不正确，它可能有bug需要你来解决。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络的权重初始化（Weight Initialization for Deep Networks）-吴恩达 深度学习 course2 1.11笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-19-course2-Week1-11-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%88Weight%20Initialization%20for%20Deep%20Networks%EF%BC%89.html</url>
    <content type="text"><![CDATA[针对梯度消失和梯度爆炸问题，我们想出了一个不完整的解决方案，虽然不能彻底解决问题，却很有用，有助于我们为神经网络更谨慎地选择随机初始化参数。 当输入的数量 n 较大时，我们希望每个 wi 的值都小一些，这样它们的和得到的 z 也较小。 要得到较小的 wi，设置Var(wi)=1/n，这里称为 Xavier initialization。 1WL = np.random.randn(WL.shape[0], WL.shape[1]) * np.sqrt(1/n) n就是我喂给的神经单元数量 这样，激活函数的输入 x 近似设置成均值为 0，标准方差为 1，相应的，神经元输出 z 的方差就正则化到 1 了。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。 将 ReLU 作为激活函数时，Var(wi)=2/n 总结，当激活函数使用 ReLU 时，Var(wi)=2/n；当激活函数使用 tanh 时，Var(wi)=1/n。 实际上，我认为所有这些公式只是给你一个起点，它们给出初始化权重矩阵的方差的默认值]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度消失 梯度爆炸（Vanishing/ Exploding gradients）-吴恩达 深度学习 course2 1.10笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-19-course2-Week1-10-%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%20%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8.html</url>
    <content type="text"><![CDATA[定义训练神经网络，尤其是深度神经所面临的一个问题就是梯度消失或梯度爆炸，也就是你训练神经网络的时候，导数或坡度有时会变得非常大，或者非常小，甚至于以指数方式变小，这加大了训练的难度。 在深度神经网络中，激活函数以与L相关的指数级数增长或下降的情况,分别称为梯度爆炸或者梯度消失。与层数L相关的导数或梯度函数，也是呈指数级增长或呈指数递减。 发生梯度消失、梯度爆炸的原因为了简单起见，假设我们使用激活函数 $$g(z) = z, b^{[l]} = 0$$ 也就是线性激活函数,且忽略了b。对于输出有： $$\hat{y} = W^{[L]}W^{[L-1]}…W^{[2]}W^{[1]}X$$ 对于 W[l]的值大于 1 的情况，激活函数的值将以指数级递增； 对于 W[l]的值小于 1 的情况，激活函数的值将以指数级递减。 虽然我只是讨论了激活函数以与L相关的指数级数增长或下降，它也适用于与层数L相关的导数或梯度函数，也是呈指数级增长或呈指数递减。 最近Microsoft对152层神经网络的研究取得了很大进展，在这样一个深度神经网络中，如果激活函数或梯度函数以与相关的指数增长或递减，它们的值将会变得极大或极小，从而导致训练难度上升，尤其是梯度指数小于时，梯度下降算法的步长会非常非常小，梯度下降算法将花费很长时间来学习。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归一化输入（Normalizing inputs）-吴恩达 深度学习 course2 1.9笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-18-course2-Week1-9-%E5%BD%92%E4%B8%80%E5%8C%96%E8%BE%93%E5%85%A5%EF%BC%88Normalizing%20inputs%EF%BC%89.html</url>
    <content type="text"><![CDATA[归一化输入的两个步骤训练神经网络，其中一个加速训练的方法就是归一化输入(Normalizing inputs)。假设一个训练集有两个特征，输入特征为2维，归一化需要两个步骤： 零均值化 归一化方差； 我们希望无论是训练集和测试集都是通过相同的均值和方差来完成归一化 标准化公式: $$x = \frac{x - \mu}{\sigma}$$ 其中， $$\mu = \frac{1}{m}\sum^m_{i=1}{x^{(i)}}$$ $$\sigma = \sqrt{\frac{1}{m}\sum^m_{i=1}{x^{(i)^2}}}$$ 为什么要归一化特征输入 在不使用标准化的成本函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了标准化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[其他正则化方法（Other regularization methods）-吴恩达 深度学习 course2 1.8笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-17-course2-Week1-8-%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95.html</url>
    <content type="text"><![CDATA[除了L2正则化和随机失活（dropout）正则化，还有几种方法可以减少神经网络中的过拟合: 数据扩增（Data Augmentation） 假设你正在拟合猫咪图片分类器，如果你想通过扩增训练数据来解决过拟合，但扩增数据代价高，而且有时候我们无法扩增数据，但我们可以通过添加这类图片来增加训练集。例如，水平翻转图片，并把它添加到训练集。所以现在训练集中有原图，还有翻转后的这张图片，所以通过水平翻转图片，训练集则可以增大一倍，因为训练集有冗余，这虽然不如我们额外收集一组新图片那么好，但这样做节省了获取更多猫咪图片的花费。 除了水平翻转图片，你也可以随意裁剪图片，这张图是把原图旋转并随意放大后裁剪的，仍能辨别出图片中的猫咪。 通过随意翻转和裁剪图片，我们可以增大数据集，额外生成假训练数据。和全新的，独立的猫咪图片数据相比，这些额外的假的数据无法包含像全新数据那么多的信息，但我们这么做基本没有花费，代价几乎为零，除了一些对抗性代价。以这种方式扩增算法数据，进而正则化数据集，减少过拟合比较廉价。 对于字符识别，我们还可以通过添加数字，随意旋转或扭曲数字来扩增数据，把这些数字添加到训练集，它们仍然是数字。为了方便说明，我对字符做了强变形处理，所以数字4看起来是波形的，其实不用对数字4做这么夸张的扭曲，只要轻微的变形就好，我做成这样是为了让大家看的更清楚。实际操作的时候，我们通常对字符做更轻微的变形处理。因为这几个4看起来有点扭曲。所以，数据扩增可作为正则化方法使用，实际功能上也与正则化相似。 早停止法（Early Stopping） 因为在训练过程中，我们希望训练误差，代价函数J都在下降，通过early stopping，我们不但可以绘制上面这些内容，还可以绘制验证集误差，它可以是验证集上的分类误差，或验证集上的代价函数，逻辑损失和对数损失等。你会发现，验证集误差通常会先呈下降趋势，然后在某个节点处开始上升。 early stopping的作用是，你会说，神经网络已经在这个迭代过程中表现得很好了，我们在此停止训练吧，得到验证集误差。 early stopping要做就是在中间点停止迭代过程，我们得到一个值中等大小的弗罗贝尼乌斯范数，与L2正则化相似，选择参数w范数较小的神经网络。 early stopping的缺点：因为提早停止梯度下降，也就是停止了优化代价函数，所以代价函数的值可能不够小，同时你又希望不出现过拟合，你没有采取不同的方式来解决这两个问题，而是用一种方法同时解决两个问题，这样做的结果是我要考虑的东西变得更复杂。 如果不用early stopping，另一种方法就是正则化，训练神经网络的时间就可能很长。我发现，这导致超级参数搜索空间更容易分解，也更容易搜索，但是缺点在于，你必须尝试很多正则化参数的值，这也导致搜索大量值的计算代价太高 Early stopping的优点是，只运行一次梯度下降，你可以找出的较小值，中间值和较大值，而L2正则化需尝试超级参数的很多值。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 dropout（Understanding Dropout）-吴恩达 深度学习 course2 1.7笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-17-course2-Week1-7-%E7%90%86%E8%A7%A3dropout.html</url>
    <content type="text"><![CDATA[直观上理解Dropout可以随机删除网络中的神经单元，他为什么可以通过正则化发挥如此大的作用呢？ 不依赖于任何一个特征，因为该单元的输入可能随时被清除 通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似； 实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化； L2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。 总结一下，dropout的功能类似于正则化，与正则化不同的是，被应用的方式不同，dropout也会有所不同，甚至更适用于不同的输入范围。 实施dropout的细节 如果你担心某些层比其它层更容易发生过拟合，可以把某些层的keep-prob值设置得比其它层更低， 缺点是为了使用交叉验证，你要搜索更多的超级参数， 另一种方案是在一些层上应用dropout，而有些层不用dropout，应用dropout的层只含有一个超级参数，就是keep-prob。 dropout常在计算机视觉应用中 计算视觉中的输入量非常大，输入太多像素，以至于没有足够的数据，所以dropout在计算机视觉中应用得比较频繁，有些计算机视觉研究人员非常喜欢用它，几乎成了默认的选择。 但要牢记一点，dropout是一种正则化方法，它有助于预防过拟合，除非算法过拟合，不然我是不会使用dropout的 它在其它领域应用得比较少，主要存在于计算机视觉领域，因为我们通常没有足够的数据，所以一直存在过拟合 dropout 大缺点dropout 的一大缺点是成本函数无法被明确定义。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将keep_prob全部设置为 1.0 后运行代码，确保 J(w,b)函数单调递减，再打开 dropout]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dropout 正则化（Dropout Regularization）-吴恩达 深度学习 course2 1.6笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-17-course2-Week1-6-dropout-%E6%AD%A3%E5%88%99%E5%8C%96.html</url>
    <content type="text"><![CDATA[dropout工作原理除了L2 正则化，还有一个非常实用的正则化方法——“Dropout（随机失活）”，我们来看看它的工作原理。 假设你在训练左图这样的神经网络，它存在过拟合，这就是dropout所要处理的，我们复制这个神经网络，dropout会遍历网络的每一层，并设置消除神经网络中节点的概率。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用backprop方法进行训练。 右图是网络节点精简后的一个样本，对于其它样本，我们照旧以抛硬币的方式设置概率，保留一类节点集合，删除其它类型的节点集合。对于每个训练样本，我们都将采用一个精简后神经网络来训练它，这种方法似乎有点怪，单纯遍历节点，编码也是随机的，可它真的有效。不过可想而知，我们针对每个训练样本训练规模极小的网络，最后你可能会认识到为什么要正则化网络，因为我们在训练极小的网络 如何实施dropout呢如何实施dropout呢？方法有几种，接下来我要讲的是最常用的方法，即inverted dropout（反向随机失活），出于完整性考虑，我们用一个三层（l=3）网络来举例说明。 首先要定义向量d 1d3 = np.random.rand(a3.shape[0],a3.shape[1]) 然后看它是否小于keep-prob 1d3 = np.random.rand(a3.shape[0],a3.shape[1]) &lt; keep_prob keep-prob是一个具体数字，它表示保留某个隐藏单元的概率. 如果用python实现该算法的话，d3则是一个布尔型数组，值为true和false 获取激活函数 1a3 =np.multiply( a3,d3) 最后,除以keep-prob参数 1a3 /= keep_prob 为了不影响z4的期望值，我们需要用a3 /= keep_prob，它将会修正或弥补我们所需的那20%，a3的期望值不会变。反向随机失活（inverted dropout）方法通过除以keep-prob，确保的期望值不变。 据我了解，目前实施dropout最常用的方法就是Inverted dropout，建议大家动手实践一下 在测试阶段，我们并未使用dropout，自然也就不用抛硬币来决定失活概率，以及要消除哪些隐藏单元了，因为在测试阶段进行预测时，我们不期望输出结果是随机的，如果测试阶段应用dropout函数，预测会受到干扰。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么正则化有利于预防过拟合呢-吴恩达 深度学习 course2 1.5笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-17-course2-Week1-5-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AD%A3%E5%88%99%E5%8C%96%E6%9C%89%E5%88%A9%E4%BA%8E%E9%A2%84%E9%98%B2%E8%BF%87%E6%8B%9F%E5%90%88%E5%91%A2.html</url>
    <content type="text"><![CDATA[直观理解直观上理解就是如果正则化λ设置得足够大，权重矩阵W被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大。 数学解释我们再来直观感受一下，正则化为什么可以预防过拟合，假设我们用的是这样的双曲线激活函数g(z) = tanh(z)（sigmoid 同理） 总结一下，如果正则化参数λ变得很大，参数W很小，z也会相对变小，此时b忽略的影响，z会相对变小，实际上，z的取值范围很小，这个激活函数，也就是曲线函数会相对呈线性，整个神经网络会计算离线性函数近的值，这个线性函数非常简单，并不是一个极复杂的高度非线性函数，不会发生过拟合。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则化（Regularization）-吴恩达 深度学习 course2 1.4笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-17-course2-Week1-4-%E6%AD%A3%E5%88%99%E5%8C%96.html</url>
    <content type="text"><![CDATA[正则化避免过拟合深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合，或减少你的网络误差。 Logistic 回归中的正则化 在逻辑回归函数中加入正则化，只需添加参数λ，也就是正则化参数。加入 L2 正则化（也称“L2 范数”）的成本函数为 $$J(w,b) = \frac{1}{m}\sum_{i=1}^mL(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2m}{||w||}^2_2$$ L2 正则化： $$\frac{\lambda}{2m}{||w||}^2_2 = \frac{\lambda}{2m}\sum_{j=1}^{n_x}w^2_j = \frac{\lambda}{2m}w^Tw$$ L1 正则化： $$\frac{\lambda}{2m}{||w||}1 = \frac{\lambda}{2m}\sum{j=1}^{n_x}{|w_j|}$$ 其中，λ 为正则化因子，是超参数。 由于 L1 正则化最后得到 w 向量中将存在大量的 0，使模型变得稀疏化，因此 人们在训练网络时，越来越倾向于使用L2 正则化。 注意，lambda在 Python 中属于保留字，所以在编程的时候，用lambd代替这里的正则化因子。 这就是在逻辑回归函数中实现正则化的过程 神经网络中的正则化 神经网络中加入正则化的成本函数为 $$J(w^{[1]}, b^{[1]}, …, w^{[L]}, b^{[L]}) = \frac{1}{m}\sum_{i=1}^mL(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2m}\sum_{l=1}^L{||w^{[l]}||}^2_F$$ 字母 L 是神经网络所含的层数。因为是一个$$n^{[l]}\times n^{[l-1]}$$的多维矩阵,有： $${||w^{[l]}||}^2_F = \sum^{n^{[l-1]}}{i=1}\sum^{n^{[l]}}{j=1}(w^{[l]}_{ij})^2$$ 该矩阵范数被称作“弗罗贝尼乌斯范数（Frobenius Norm）”，用下标 F 标注. 如何使用该范数实现梯度下降呢？backprop计算出 dw 的值。在加入正则化项后，梯度变为 $$dW^{[l]}= \frac{\partial L}{\partial w^{[l]}} +\frac{\lambda}{m}W^{[l]}$$ 代入梯度更新公式： $$W^{[l]} := W^{[l]}-\alpha dW^{[l]}$$ 可得： $$W^{[l]} := W^{[l]} - \alpha [\frac{\partial L}{\partial w^{[l]}} + \frac{\lambda}{m}W^{[l]}]$$ $$= W^{[l]} - \alpha \frac{\lambda}{m}W^{[l]} - \alpha \frac{\partial L}{\partial w^{[l]}}$$ $$= (1 - \frac{\alpha\lambda}{m})W^{[l]} - \alpha \frac{\partial L}{\partial w^{[l]}}$$ 其中，因为 1−αλ/m&lt;1，会给原来的 W[l]一个衰减的参数，因此 L2 正则化项也被称为权重衰减（Weight Decay）。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[训练神经网络用到的基本方法-吴恩达 深度学习 course2 1.3笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-17-course2-Week1-3-%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%94%A8%E5%88%B0%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95.html</url>
    <content type="text"><![CDATA[模型训练的方法 存在高偏差(high bias)： 扩大网络规模，如添加隐藏层或隐藏单元数目； 寻找合适的网络架构，使用更大的 NN 结构； 花费更长时间训练。 初始模型训练完成后，我首先要知道算法的偏差高不高，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至无法拟合训练集，那么你要做的就是选择一个新的网络，比如含有更多隐藏层或者隐藏单元的网络，或者花费更多时间来训练网络，或者尝试更先进的优化算法， 训练学习算法时，我会不断尝试这些方法，直到解决掉偏差问题，这是最低标准，反复尝试，直到可以拟合数据为止，至少能够拟合训练集。 存在高方差(high varience)： 获取更多的数据； 正则化（regularization）； 寻找更合适的网络结构。 一旦偏差降低到可以接受的数值，检查一下方差有没有问题，为了评估方差，我们要查看验证集性能，我们能从一个性能理想的训练集推断出验证集的性能是否也理想，如果方差高，最好的解决办法就是采用更多数据，如果你能做到，会有一定的帮助，但有时候，我们无法获得更多数据，我们也可以尝试通过正则化来减少过拟合。有时候我们不得不反复尝试，但是，如果能找到更合适的神经网络框架，有时它可能会一箭双雕，同时减少方差和偏差。 两点要注意的第一点，高偏差和高方差是两种不同的情况，我们后续要尝试的方法也可能完全不同，我通常会用训练验证集来诊断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方法。举个例子，如果算法存在高偏差问题，准备更多训练数据其实也没什么用处，至少这不是更有效的方法，所以大家要清楚存在的问题是偏差还是方差，还是两者都有问题，明确这一点有助于我们选择出最有效的方法。 第二点，在机器学习的初期阶段，关于所谓的偏差方差权衡的讨论屡见不鲜，原因是我们能尝试的方法有很多。可以增加偏差，减少方差，也可以减少偏差，增加方差，但是在深度学习的早期阶段，我们没有太多工具可以做到只减少偏差或方差却不影响到另一方。但在当前的深度学习和大数据时代，只要持续训练一个更大的网络，只要准备了更多数据，那么也并非只有这两种情况，我们假定是这样，那么，只要正则适度，通常构建一个更大的网络便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。这两步实际要做的工作是：训练网络，选择网络或者准备更多数据。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[偏差Bias 方差Variance-吴恩达 深度学习 course2 1.2笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-17-course2-Week1-2-%E5%81%8F%E5%B7%AE-%E6%96%B9%E5%B7%AE.html</url>
    <content type="text"><![CDATA[泛化误差泛化误差可分解为偏差、方差与噪声之和（Error = Bias + Variance + Noise）： 偏差：度量了学习算法的期望预测与真实结果的偏离程度，即模型本身的精准度，反应出算法的拟合能力。 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即模型的稳定性，反应出预测的波动情况。 噪声：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了学习问题本身的难度。 偏差与方差的关系偏差与方差之间按照高低，可以组合成四种关系: 低偏差 高方差 表示模型准确但是稳定性差，对验证数据&amp;测试数据的拟合能力差，即是模型的泛化能力差，产生了过拟合(Overfitting)。 高偏差 低方差 表示模型的准确度差，对数据的拟合能力弱，产生了欠拟合(Underfitting)。 高偏差高方差 表示模型既不准确又不稳定。 低偏差低方差 表示模型既准确又稳定，效果最好，但是现实中这种情形很少遇见。 过拟合与欠拟合由上面的分析可知，高方差往往预示着过拟合，高偏差则是欠拟合。 避免欠拟合(拟合太差)1、增加训练样本数据 2、设计更复杂的神经网络模型 3、增加迭代次数 4、更好的优化函数 5、调整超参数值 避免过拟合(拟合过度，泛化太差)1、设计更简单的神经网络模型 2、增加训练样本数据 3、正则化。在损失函数后面添加上L2正则项 4、使用dropout。随机性使得网络中的部分神经元失效，效果上类似将模型变得更简单。 5、调整超参数值 6、尝试其他模型 7、提前结束训练(early stopping)。即是提前结束优化损失函数。 简单小结在实际工程中，通常可以按下面的来操作 贝叶斯(最优)误差 ： 理论上的最小误差值(通常比人类误差小) 可避免偏差 ：训练误差 与 贝叶斯误差 之间的差值 方差：验证集误差 与 训练误差 的差值 当 可避免偏差 大于 方差 时，发生 欠拟合。 当 方差 大于 可避免偏差 时，发生 过拟合。 在训练模型时对照以上描述，有助于定位问题，更快找到最适合的模型。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[训练，验证，测试集（Train ，Dev， Test sets）-吴恩达 深度学习 course2 1.1笔记]]></title>
    <url>%2FDeepLearning%2F2018-04-17-course2-Week1-1-%E8%AE%AD%E7%BB%83-%E9%AA%8C%E8%AF%81-%E6%B5%8B%E8%AF%95%E9%9B%86.html</url>
    <content type="text"><![CDATA[在配置训练、验证和测试数据集的过程中做出正确决策会在很大程度上帮助大家创建高效的神经网络。训练神经网络时，我们需要做出很多决策，例如： 神经网络分多少层 每层含有多少个隐藏单元 学习速率是多少 各层采用哪些激活函数 现如今，深度学习已经在自然语言处理，计算机视觉，语音识别以及结构化数据应用等众多领域取得巨大成功 结构化数据无所不包，从广告到网络搜索。其中网络搜索不仅包括网络搜索引擎，还包括购物网站，从所有根据搜索栏词条传输结果的网站。再到计算机安全，物流，比如判断司机去哪接送货，范围之广，不胜枚举。 应用深度学习是一个典型的迭代过程，需要多次循环往复，才能为应用程序找到一个称心的神经网络，因此循环该过程的效率是决定项目进展速度的一个关键因素，而创建高质量的训练数据集，验证集和测试集也有助于提高循环效率。 在建立模型的过程中，数据会被划分为以下几个部分： 训练集（train set）：用训练集对算法或模型进行训练过程； 验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行交叉验证，选择出最好的模型； 测试集（test set）：最后利用测试集对模型进行测试，获取模型运行的无偏估计（对学习方法进行评估）。 对小数据量时代（如 100、1000、10000 的数据量大小） 无验证集的情况：70%训练集，30%测试集 有验证集的情况：60%训练，20%验证和20%测试集 但是在大数据时代，我们现在的数据量可能是百万级别，那么验证集和测试集占数据总量的比例会趋向于变得更小。 数据集规模较大的，验证集和测试集要小于数据总量的20%或10%。 100 万数据量：98% / 1% / 1%； 超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%） 根据经验，我建议大家要确保验证集和测试集的数据来自同一分布。 最后一点，就算没有测试集也不要紧，测试集的目的是对最终所选定的神经网络系统做出无偏估计，如果不需要无偏估计，也可以不设置测试集。]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>DeepLearning 吴恩达</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法培训视频分享]]></title>
    <url>%2Falgorithm%2F2018-04-16-%E7%AE%97%E6%B3%95%E5%9F%B9%E8%AE%AD%E8%A7%86%E9%A2%91%E5%88%86%E4%BA%AB.html</url>
    <content type="text"><![CDATA[2018牛客网 算法初级班 算法进阶班 视频 java数据结构算法 BAT算法 链接：https://pan.baidu.com/s/15eUjRuxGFwlqPiLny6_FYw 密码：ftd8 LeetCode面试算法刷题 视频/课件/代码 数据结构与算法/视频教程。 链接：https://pan.baidu.com/s/1x-CkJDc_gKdckNW14zgDlQ 密码：rhrt 需要系统的刷算法题的拿走不谢！]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶供应商竞争力排行榜]]></title>
    <url>%2Fself-driving%2F2018-04-15-self-driving-company-Ranking-4.html</url>
    <content type="text"><![CDATA[这些企业将通过四个维度进行分类和排名，分别是： 综合竞争力排行榜 整车制造企业竞争力排行榜 初创企业竞争力排行榜 供应商竞争力排行榜 科技公司和供应商排行榜 事实上，这波无人驾驶浪潮的源动力是科技公司，汽车企业还是被动跟随者。汽车行业的优势在于硬件有着极高的门槛，同时有着强劲的财务平衡表。然而车企必须颠覆自己，否则恐怕会被别人颠覆。 幸运的是，中国有着越来越多卓越的科技公司，这些企业的领导者有着成为全球领袖的雄心壮志。无人驾驶产业的竞争是各个国家之间：企业家、人才、科技、教育、资金以及政府执行力的全方位竞争。 无人驾驶核心供应商 无人驾驶产业会诞生具有很强竞争力的供应商，尤其是芯片和激光雷达领域，车评君简要加以梳理。值得引起关注的是，这些核心供应商全部都在美国。- 芯片领域进入门槛非常高，初创公司在里面几乎不会有机会。但是，谷歌也推出了自己专门支持人工智能运算的芯片TPU，声称性能比英伟达的GPU能力更强，引发英伟达CEO黄仁勋的震怒。 另外，苹果iphone的芯片均自己设计，更可怕的是，该公司也推出了自己的GPU，导致其GPU供应商股价腰斩。芯片行业还有一个巨头，是TI，这家公司拟以164亿美元收购AMD，AMD的GPU可与英伟达一拼。 Lidar看起来威力登的领先优势不会持续太久，一方面谷歌已经将Lidar的成本大幅度降低了90%。同时，德系零部件三强几乎已全部进入Lidar制造领域，这看起来开始变成了红海。]]></content>
      <categories>
        <category>self-driving</category>
      </categories>
      <tags>
        <tag>无人驾驶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶初创企业竞争力排行排行榜]]></title>
    <url>%2Fself-driving%2F2018-04-15-self-driving-company-Ranking-3.html</url>
    <content type="text"><![CDATA[这些企业将通过四个维度进行分类和排名，分别是： 综合竞争力排行榜 整车制造企业竞争力排行榜 初创企业竞争力排行榜 供应商竞争力排行榜初创企业竞争力排行 中国有着世界上最好的创业环境，涌现出了大量的无人驾驶初创公司，百度系是最大的主力，微软亚洲研究院也有所贡献。 从无人驾驶技术的发展来看，依托知名高校是其发展的必要条件。在全世界范围内，为无人驾驶贡献做大的高校为MIT，卡耐基梅隆大学，斯坦福大学，密歇根大学，清华大学和牛津大学。 无人驾驶的技术大战表明，未来世界的竞争，科学技术将变得日趋重要。具备全球范围内领先的研究型大学的建设将变得极其关键。一方面，能够在基础技术研究方面处于领先，同时提供源源不断的人才保障。中国人一定要大力投资教育。]]></content>
      <categories>
        <category>self-driving</category>
      </categories>
      <tags>
        <tag>无人驾驶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶整车制造商竞争力排行榜]]></title>
    <url>%2Fself-driving%2F2018-04-15-self-driving-company-Ranking-2.html</url>
    <content type="text"><![CDATA[这些企业将通过四个维度进行分类和排名，分别是： 综合竞争力排行榜 整车制造企业竞争力排行榜 初创企业竞争力排行榜 供应商竞争力排行榜 整车制造商竞争力排行榜 无人驾驶技术的决定力量还是整车制造商，车评君选了全球范围内23家制造商进入榜单，目前看来这些车企在无人驾驶上具备不错的竞争力，并是这个市场强有力的竞争者。 从竞争力的角度而言，美系车企实力非常强劲，他们的每一家制造商都能够进入综合榜的top10。中国有大量的整车制造商在做无人驾驶，但在研发费用上的真金白银的投入并不多，更多的时候是噱头。]]></content>
      <categories>
        <category>self-driving</category>
      </categories>
      <tags>
        <tag>无人驾驶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶竞争力排行榜 目录]]></title>
    <url>%2Fself-driving%2F2018-04-15-self-driving-company-Ranking.html</url>
    <content type="text"><![CDATA[这些企业将通过四个维度进行分类和排名，分别是： 综合竞争力排行榜 整车制造企业竞争力排行榜 初创企业竞争力排行榜 供应商竞争力排行榜 总表 文章来源：https://www.d1ev.com/kol/50962]]></content>
      <categories>
        <category>self-driving</category>
      </categories>
      <tags>
        <tag>无人驾驶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶综合竞争力排名]]></title>
    <url>%2Fself-driving%2F2018-04-15-self-driving-company-Ranking-1.html</url>
    <content type="text"><![CDATA[这些企业将通过四个维度进行分类和排名，分别是： 综合竞争力排行榜 整车制造企业竞争力排行榜 初创企业竞争力排行榜 供应商竞争力排行榜综合竞争力排行榜 从整体竞争力而言，谷歌和百度两家依然实力最强。同时，这两家也是被挖人最多、员工离职创业最多的企业。目前的无人驾驶初创公司美国以谷歌系为主，中国以百度系为主。 通用进度很快，最新的消息是在下个月将会投放全世界规模最庞大的无人驾驶测试车队，数量达到300辆，是其他所有29家在硅谷参与测试的车队数量之和。苹果也取得无人驾驶的测试牌照，这些改装过的雷克萨斯SUV将持续出行的硅谷的马路上。 丰田汽车有着很好的技术研发领军人物，然而日本车企的保守会限制他们的进步。英特尔对Mobileye的收购是成功的，这极大地提升了这家公司在无人驾驶竞赛中的竞争力。]]></content>
      <categories>
        <category>self-driving</category>
      </categories>
      <tags>
        <tag>无人驾驶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS一键安装脚本及使用教程-《用ROS学习机器人编程的系统方法》]]></title>
    <url>%2Fros_tutorial%2F2018-04-13-ROS%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B.html</url>
    <content type="text"><![CDATA[对新手来说，ROS配置环境步骤太过繁琐，打击了新手的学习兴趣。本教程采用国外大牛写的一键安装脚本，方便大家配置ROS开发环境. 首先需要注意的是：ubuntu14.04下请安装ROS indigo,而 ubuntu 16.04下安装ROS kinetic版本 . git安装你需要在你的机器上安装“git”来使用这些脚本。如果“git”还没有安装在您的机器上，用下面命令安装： sudo apt-get --yes --force-yes install git 下载脚本并修改脚本权限 将learning_ros_setup_scripts克隆到计算机上的任意位置： git clone https://github.com/wsnewman/learning_ros_setup_scripts.git 下载完脚本后，通过输入以下命令将目录更改为learning_ros_setup_scripts： cd learning_ros_setup_scripts 键入以下命令添加脚本的执行权限： chmod +x *.sh ROS indigo 安装 请键入以下命令运行脚本install_ros_and_tools.sh： ./install_ros_and_tools.sh (或者 bash install_ros_and_tools.sh) 执行完之后，ROS即安装完成。同时，《用ROS学习机器人编程的系统方法》教程对应的相关程序也安装成功。 工作空间 设定配置《用ROS学习机器人编程的系统方法》教程对应的ROS工作空间（workspace），请使用setup_workspace_learning_ros.sh脚本。这需要使用你的github用户名和电子邮件作为脚本的参数： ./setup_workspace_learning_ros.sh github_username github@email.com (或者 bash setup_workspace_learning_ros.sh github_username github@email.com) 其中github_username是您在github上的用户名，而github@email.com是您的电子邮件地址，即您的github帐户。 ROS kinetic 安装 安装了indigo版本的请跳过此部分。 如果您需要安装ROS kinetic。只需将安装indigo过程的脚本对应换成 install_ros_and_tools_kinetic.sh及 setup_workspace_learning_ros_kinetic.sh， 其它另外ROS 维基官网 也提供了两行安装脚本 可以用来在PC上(ubuntu 13.10 和14.04 LTS)安装ROS Indigo的脚本文件。代码如下 12345wget https://raw.githubusercontent.com/oroca/oroca-ros-pkg/master/ros_install.sh &amp;&amp; ./ros_install.sh %NAME_CATKIN_WS% %NAME_ROS_DISTRO_LOWERCASE%(或者)wget https://raw.githubusercontent.com/oroca/oroca-ros-pkg/master/ros_install.sh &amp;&amp; chmod 755 ./ros_install.sh &amp;&amp; ./ros_install.sh catkin_ws_oroca indigo 参考网站： 原作者：https://github.com/wsnewman/learning_ros_setup_scripts 中文教程： https://github.com/songapore/learning_ros_setup_scripts wiki两行安装脚本 : http://wiki.ros.org/ROS/Installation/TwoLineInstall]]></content>
      <categories>
        <category>ros教程</category>
      </categories>
      <tags>
        <tag>ros教程 用ROS学习机器人编程的系统方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS环境变量]]></title>
    <url>%2Fros_tutorial%2F2018-03-28-ROS%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F.html</url>
    <content type="text"><![CDATA[本文翻译http://wiki.ros.org/ROS/EnvironmentVariables 在ROS中，可以设置很多环境变量。最需要理解的是ROS_MASTER_URI, ROS_ROOT和 ROS_PACKAGE_PATH，因为他们频繁的在系统和文件中被用到。 环境变量在ROS中有多重角色：寻找packages(Finding packages )：首先，ROS_ROOT和 ROS_PACKAGE_PATH 使ROS在系统文件(filesystem)中能够定位packages和stacks。同样必须设置PYTHONPATH，这样python解释器才能找到ROS库。 影响一个节点运行时间(Effecting a Node runtime ):有几个环境变量会影响节点的运行`。 -ROS_MASTER_URI是一个重要的环境变量来告诉节点Master（主机）在哪里。 ROS_IP和ROS_HOSTNAME影响一个节点的网络地址， ROS_NAMESPACE能够让你改变命名空间。 ROS_LOG_DIR可以让你设置日志文件写入的目录。这些也可以被映射参数覆盖，映射参数优先于环境变量。 修改构建系统(Modifying the build system): ROS_BINDEPS_PATH,ROS_BOOST_ROOT，ROS_PARALLEL_JOBS和ROS_LANG_DISABLE影响在哪里寻找库，怎样构建他们，构建哪一个。 必需的ROS环境变量 大部分系统都要设置ROS_PACKGE_PATH， ROS只需要环境变量ROS_ROOT,ROS_MASTER_URI和PYTHONPATH。 默认通过sourcing /opt/ros/fuerte/setup.bash来自动设置他们。 ROS_ROOTROS_ROOT设置ROS core包安装的位置。 export ROS_ROOT=/home/user/ros/ros export PATH=$ROS_ROOT/bin:$PATH ROS_MASTER_URIROS_MASTER_URI是一个必需的设置来告诉节点在哪里定位master。应该设置master的XML-RPC URI。使用localhost时需要格外小心，因为远程启动节点可能会导致意想不到的结果。 export ROS_MASTER_URI=http://mia:11311/ PYTHONPATH ROS需要PYTHONPATH更新，尽管你可能不用Python编程！很多ROS基础工具都依靠Python，需要连接到roslib包来bootstrapping。 export PYTHONPATH=$PYTHONPATH:$ROS_ROOT/core/roslib/src 其他的 PATH环境变量ROS_PACKAGE_PATHROS_PACKAGE_PATH是一个可选，但很常用的环境变量，能够让你从源添加更多的ROS包到当前环境。ROS_PACKAGE_PATH可以由一个或多个路径组成，路径之间由标准操作系统路径间隔符(在Unix类的系统中，用’:’)分隔。这些有序的路径告诉ROS系统到哪里搜索更多的ROS包。如果多个包有相同的名字，ROS会首先选择出现在ROS_PACKAGE_PATH的那个。 export ROS_PACKAGE_PATH=/home/user/ros/ros-pkg:/another/path 注意ROS_PACKAGE_PATH的每个条目都被重复查找-路径中提到的包都会被找到。 引入catkin后，ROS_PACKAGE_PATH过时了，只是用来与rosbuild包保持向后兼容。 系统数据 环境变量ROS_HOME默认，ROS写数据到~/.ros。可以通过设置ROS_HOME来改变这个位置。也可以在~/.ros中更改某个目录的位置(例如，ROS_TEST_RESULTS_DIR,ROS_LOG_DIR)。 ROS_LOG_DIR 默认，ROS写内部日志文件到ROS_HOME/log。如果这个位置对ROS不可写，或者希望日志文件写到别的地方，设置ROS_LOG_DIR到其他路径。 ROS_TEST_RESULTS_DIR 测试结果要写到的目录。 其他的 Bash环境变量ROS_LOCATIONSROS_LOCATIONS是一个可选的环境变量，为有用的位置提供键名。它是key-location对的分隔列表。每个key-location对用一个=分隔。例如: export ROS_LOCATIONS=&quot;rospkg=/path/to/rospkg:stairpkg=/path/to/stairpkg&quot; 然后这些键就可以用一些工具了，如roscd。 ROS_WORKSPACEROS_WORKSPACE由工具rosinstall/rosws引进的，当创建一个workspace时，通过这些工具生成的setup.sh设置。它指向workspace的文件夹，通过使用rosws命令使用，作为命令的默认目标。 不带参数的调用时，fuerte中的roscd工具也改用这个变量。此前，它默认改变ROS_ROOT. 节点 环境变量ROS_IP/ROS_HOSTNAMEROS_IP和ROS_HOSTNAME是可选的环境变量，用来设置ROS节点或工具的公开网地址。这两个选项是互斥的，如果两者都设置优先使用ROS_HOSTNAME。 如果你指定一个IP地址，使用ROS_IP；如果制定一个主机名(a host name)，使用ROS_HOSTNAME。当一个ROS成员报告URI给master或者其他成员，这个值就会被用到。这个设置只用在一台计算机有多个地址，需要强制ROS到特定的一个的情况。 除了’localhost’(本地主机),ROS成员绑定到所有可用的网络接口，他不影响实际绑定地址。如果这个值设定为本地主机，ROS成员只绑定在环回接口。这将会阻止远程成员与本地成员交流。 ROS_NAMESPACEROS_NAMESPACE可以让你推一个节点到一个命名空间。节点中的所有名字都会相对于这个值解析，包括映射名称。 ROSCONSOLE_CONFIG_FIE这是一个roscpp指定环境变量。Rosconsole让你定义用在log4cxx的配置文件，通过环境变量ROSCONSOLE_CONFIG_FILE定义。在这个配置文件中有任何定义都会覆盖默认的配置文件。 Console Output Formatting 控制台输出格式Rosconsole允许指定怎样通过环境变量ROSCONSOLE_FORMAT在控制台输出。默认等效于： export ROSCONSOLE_FORMAT=&#39;[${severity}] [${time}]: ${message}&#39; ROS_PYTHON_LOG_CONFIG_FILE 特定 rospy, rosmaster, roslaunch, and rostest.对于这些工具，可以指定使用自己的Python logging配置文件来代替默认配置文件，它保存在$ROS_ROOT/config/python_logging.conf. 构建系统环境变量 为了更好的了解这些环境变量，请看ROS Build System部分。 ROS_BOOST_ROOTROS_BOOST_ROOT是一个可选的环境变量，能让你覆盖哪里去寻找激励。如果ROS_BOOST_ROOT不设置，默认使用ROS_BINDEPS_PATH。 ROS_PARALLEL_JOBS这个变量的值，如果设置，构建包的时候会传递给make。目的是充分使用多处理器机器。例如，如果有8处理器/核，想尽可能多的运行并行任务，只要系统负荷小于8，通过限制任务为8，可以在启动时阻止过冲： export ROS_PARALLEL_JOBS=&apos;-j8 -l8&apos; 或者，可以使用-j标识带一个参数来并行运行最多8个任务，系统负载独立： export ROS_PARALLEL_JOBS=-j8 强烈建议使用-l标识来设置并行系统相关限制。在一个大的构建中并行过多可能会耗尽系统内存。 可以接受多少系统负载取决于有多少内核。 ROS_LANG_DISABLE消息生成器/客户端库包名称应禁用一个冒号分隔的列表。Message-generation will not happen for languages in this list. 用catkin构建的包需要需要列出应当被忽视的消息生成器的名字，例如： export ROS_LANG_DISABLE=genlisp 用rosbuild构建的包需要列出应当被忽视的消息生成器及客户端库的名字，例如： export ROS_LANG_DISABLE=genlisp:roslisp 当忽视掉消息生成器的rosbuild和CMake配置步骤，将会显示一个警告，客户端库(例如，roslisp)不是一个已知的消息生成器。这个警告可以安全的忽略掉。 注意，禁用语言之前，首先必须确定你使用的代码没有与这个语言绑定。 ROS_OS_OVERRIDE格式：”OS_NAME:OS_VERSION_STRING”，这将会强制检测Ubuntu Lucid: export ROS_OS_OVERRIDE=ubuntu:10.04 如果定义，这将覆盖系统的自动检测。在外来平台上调试rosdep依赖性时，当平台很相似可能需要强制，或自动检测失败时，很有用。]]></content>
      <categories>
        <category>ros教程</category>
      </categories>
      <tags>
        <tag>ros教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS开发基础-4.ROS服务消息(.srv)]]></title>
    <url>%2Fros_tutorial%2F2018-03-27-ROS%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80-4.ROS%E6%9C%8D%E5%8A%A1%E6%B6%88%E6%81%AF(.srv).html</url>
    <content type="text"><![CDATA[服务描述的内容保存在 .srv 文件中 .srv 文件包括 request 和response 两部分，两者之间用 ‘—‘ 例子如下 #request constants string str #response constants string str 创建srv设置工作空间$ source ~/catkin_ws/devel/setup.bash 添加 .srv 文件在src/my_msgs功能包 目录下 新建 .srv 文件 ，并添加 内容 更新 package.xml 文件打开my_msgs功能包的package.xml文件，确保如下两行 命令没有被注释掉. &lt;build_depend&gt; message_generation &lt;/build_depend&gt; &lt;run_depend&gt; message_runtime &lt;/run_depend&gt; 编译时需要 message_generation，运行时需要 message_runtime 更新CMakeList.txt文件 打开CMakeList.txt文件，在 find_package(…)中添加 message_generation，这样在编译之后就可以生成服务了。 find_package(catkin REQUIRED COMPONENTS roscpp rospy std_msgs message_generation ) 在CMakeList.txt文件中 找到 catkin_package(…) 并添加 CATKIN_DEPENDS roscpp rospy std_msgs message_runtime 在CMakeList.txt文件中 找到如下代码 #add_service_files( #FILES #Service1.srv #Service2.srv #) 去掉前面的注释#，并添加新建的.srv文件，如下 add_service_files( FILES #Service1.srv #Service2.srv my_srv.srv ) 在CMakeList.txt文件中 找到如下代码 #generate_messages( #DEPENDENCIES #std_msgs #) 去掉前面的注释# 重新 编译 功能包$ cd ~/catkin_ws$ catkin_make 使用rossrv命令$ rossrv show my_msgs/My_srv 结果应为 int64 reqint64 res 这说明.srv消息已经可以使用了。由上面的介绍可知，.srv 与 .msg 的创建过程类似。]]></content>
      <categories>
        <category>ros教程</category>
      </categories>
      <tags>
        <tag>ros教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS开发基础-3.ROS消息]]></title>
    <url>%2Fros_tutorial%2F2018-03-26-ROS%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80-3.ROS%E6%B6%88%E6%81%AF(messages).html</url>
    <content type="text"><![CDATA[消息是节点之间 主题通信 的数据结构，相当于C语言中的结构体，它支持标准的数据类型（如整型、浮点型、布尔型等）。 消息的变量保存在 .msg 文件中。创建消息的过程如下：创建功能包 在工作空间src文件夹下新建my_msgs功能包。 $ source ~/catkin_ws/devel/setup.bash $ cd ~/catkin_ws/src $ catkin_create_pkg my_msgs std_msgs rospy roscpp 创建msg文件夹在功能包 路径下 新建一个 名为 msg的文件夹，并添加一个名为 MyRobotState.msg的文件，该文件的内容为： float32 myrobot_contact 更新package.xml文件打开my_msgs功能包的package.xml文件，确保如下两行 命令没有被注释掉. &lt;build_depend&gt; message_generation &lt;/build_depend&gt; &lt;run_depend&gt; message_runtime &lt;/run_depend&gt; 编译时需要 message_generation，运行时需要 message_runtime 更新CMakeList.txt文件 打开CMakeList.txt文件，在 find_package(…)中添加 message_generation，这样在编译之后就可以生成消息了。 find_package(catkin REQUIRED COMPONENTS roscpp rospy std_msgs message_generation ) 在CMakeList.txt文件中 找到 catkin_package(…) 并添加 CATKIN_DEPENDS roscpp rospy std_msgs message_runtime 在CMakeList.txt文件中 找到如下代码 #add_message_files( #FILES #Message1.msg #Message2.msg #) 去掉前面的注释#，并添加新建的.msg文件，如下 add_message_files( FILES #Message1.msg #Message2.msg MyRobotState.msg ) 在CMakeList.txt文件中 找到如下代码 #generate_messages( #DEPENDENCIES #std_msgs #) 去掉前面的注释# 重新 编译 功能包$ cd ~/catkin_ws$ catkin_make 执行如下命令$ rosmsg show my_msgs/MyRobotState 输出结果：float32 myrobot_contact 。说明已经成功定义了消息]]></content>
      <categories>
        <category>ros教程</category>
      </categories>
      <tags>
        <tag>ros教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS开发基础-2.ROS节点]]></title>
    <url>%2Fros_tutorial%2F2018-03-25-ROS%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80-2.ROS%E8%8A%82%E7%82%B9(nodes).html</url>
    <content type="text"><![CDATA[一个节点其实只不过是ROS程序包中的一个可执行文件。 ROS节点可以使用ROS客户库与其他节点通信。 节点可以发布或接收一个话题。 节点也可以提供或使用某种服务。 （节点是ros中非常重要的一个概念，为了帮助初学者理解这个概念，这里举一个通俗的例子： 例如，咱们有一个机器人，和一个遥控器，那么这个机器人和遥控器开始工作后，就是两个节点。遥控器起到了下达指 令的作用；机器人负责监听遥控器下达的指令，完成相应动作。从这里我们可以看出，节点是一个能执行特定工作任 务的工作单元，并且能够相互通信，从而实现一个机器人系统整体的功能。在这里我们把遥控器和机器人简单定义为两个节点，实际上在机器人中根据控制器、传感器、执行机构等不同组成模块，还可以将其进一步细分为更多的节点，这个是根据用户编写的程序来定义的。）]]></content>
      <categories>
        <category>ros教程</category>
      </categories>
      <tags>
        <tag>ros教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS开发基础-1.ROS功能包]]></title>
    <url>%2Fros_tutorial%2F2018-03-24-ROS%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80-1.ROS%E5%8A%9F%E8%83%BD%E5%8C%85(packages).html</url>
    <content type="text"><![CDATA[创建工作空间 工作空间类似于我们的工程文件夹。 创建一个空的catkin工作空间$ mkdir -p ~/catkin_ws/src $ cd ~/catkin_ws/src $ catkin_init_workspace 编译该工作空间$ cd ~/catkin_ws/ $ catkin_make 设置工作空间 环境变量$ cd ~/catkin_ws/ $ source devel/setup.bash 输入echo $ROS_PACKAGE_PATH，就可以看到添加的 环境变量了 创建功能包先将ROS的当前工作空间设为 catkin_ws$ cd ~/catkin_ws/ $ source devel/setup.bash 然后在 ~/catkin_ws/src目录下创建 功能包$ cd ~/catkin_ws/src $ catkin_create_pkg my_pkg std_msgs rospy roscpp 在工作空间的src文件夹下创建 my_pkg 功能包 功能包目录下有 package.xml , CMakeLists.txt 文件,及 src,include 子文件夹。 所有的 executable files 位于 ~/catkin_ws/devel/lib 所有的 include files 位于 ~/catkin_ws/devel/include 编译 所有功能包$ cd ~/catkin_ws/ $ catkin_make 编译 单个功能包$ cd ~/catkin_ws/ $ catkin_make --pkg package_name]]></content>
      <categories>
        <category>ros教程</category>
      </categories>
      <tags>
        <tag>ros教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS开发基础-0.ROS基本命令]]></title>
    <url>%2Fros_tutorial%2F2018-03-23-ROS%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80-0.ROS%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[功能包命令功能包类似于 工程项目的 文件夹 rospack (ros + pack（age）)rospack 用于获取功能包的相关信息，格式为 rospack &lt;command&gt; [package_name] 例如： rospack help//输出rospack的使用方法 rospack find [package_name]//查找并返回功能包的绝对路径 rospack depends [package_name]//输出功能包的所以依赖项 roscd (ros + cd )改变当前路径 到指定的 功能包，格式为 roscd [package_name/[subdir]]相当于rospack find 加上 cd命令的组合。 tips：roscd 和其他ROS命令工具一样，只会查找 ROS_PACKAGE_PATH路径下的功能包。 可使用echo $ ROS_PACKAGE_PATH查看功能包路径信息 roscd log 列出ROS log所在目录 rosls列出功能包下包含的文件/文件夹，格式为 rosls [package_name/[subdir]] catkin_create_pkg 创建功能包catkin_create_pkg 用来创建catkin 功能包 catkin_create_pkg [package_name] [depend1] [depend2] [depend3] 后面的depens依赖包 ，相当于程序所包含的头文件 ##catkin_make 编译功能包cd命令切换到需要编译的工作空间下，输入 catkin_make ROS 核心命令roscore (ros+core)在运行ros节点之前，必须先执行roscore命令。 ##rosrun(ros+run)rosrun 运行ROS节点，命令格式为： `rosrun [pack_name] [node_name]` ##rosnode(ros+node)显示正在运行的节点信息。 rosnode list//列出当前正在运行的节点 rosnode info [node_name]//输出改节点信息。包括发布者，订阅者，及服务等信息 rosnode kill [node_name]//结束正在运行的节点 rosmsg/rossrv rosmsg显示消息数据 的定义信息。rossrv显示服务数据 的定义信息。 运行rosmsg -h 查看rosmsg 命令的使用方法。 rosmsg show 显示消息中各个变量的定义 rosmsg list 列出所有消息 rosmsg md5 显示消息的MD5值 rosmsg package 列出功能包中所有的消息 rosmsg packages 列出某个消息的所以功能包 rostopic (ros+topic)查看节点的 主题信息 rostopic -h 查看使用方法 `rostopic bw //display bandwidth used by topic` `rostopic echo //print messages to screen` `rostopic find //find topic by type` `rostopic hz // dispaly publishing rate of topic` `rostopic info //print information about active topic ` `rostopic list //list active topics` `rostopic ;ub // publish data to topic` `rostopic type //print topci type` rosservicerosservice -h 查看使用方法 `rosservice list //输出当前活动服务的信息` `roservice call //请求服务` `rosservice type //输出服务的类型` `roservice find //通过类型查找服务` `rosservice uri //输出服务ROSRPC uri` rosparam 用来保存和设置ROS参数服务器中的数据。 参数服务器可以储存整形、浮点型、布尔型、字典及列表 参数服务器 语法格式采用 YAML语言 YAML语言中：1表示整形，1.0表示浮点型，one表示字符串，true表示布尔型，[1,2,3]表示整形列表，{a:b,c:d}表示字典 rosparam用法 rosparam set [param_name] //设置参数 rosparam get [param_name] //获取参数 rosparam load [file_name] [namespace] //从一个文件中加载参数 rosparam dump [file_name] [namespace] //写参数到一个文件 rosparam delete //删除一个参数 rosparam list //列出参数的名称 roslaunch roslaunch可以按照.launch文件的描述方式 启动节点 使用方法为： roslaunch [package] [filename.launch] rosbag .bag 是ROS中用来存储消息数据的文件格式 rosbag命令可以用来处理.bag文件 它的功能包括：记录（record）、总结（info）、回放（play）、检查（check）、修复（fix）等 rosbag record 订阅一个主题，并将消息的内容写入一个bag文件中 rosbag info 总结bag文件的内容，包括开始和结束的时间、主题、消息个数、大小写等 rosbag play 读取bag文件的内容，并以时间同步的方式回放。暂停按空格键，逐步查看消息按S键]]></content>
      <categories>
        <category>ros教程</category>
      </categories>
      <tags>
        <tag>ros教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS教程-1.1 ROS常见概念-《用ROS学习机器人编程的系统方法》]]></title>
    <url>%2Fros_tutorial%2F2018-03-22-ROS%E6%95%99%E7%A8%8B-1.1%20ROS%E5%B8%B8%E8%A7%81%E6%A6%82%E5%BF%B5-%E3%80%8A%E7%94%A8ROS%E5%AD%A6%E4%B9%A0%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%BC%96%E7%A8%8B%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B.html</url>
    <content type="text"><![CDATA[知识点总结 节点之间的通信是ROS的核心。 节点之间的通信使用 messages， topics，roscore， publishers,subscribers,services等 roscore负责所有node间的交流。 roscore 必须最先启动，才能运行其它node。 roscore有且只能有一个 在运行。运行roscore的终端（Terminal）不能做其它任务。 节点可通过topic交流。subscriber只需要知道topic的名称而不需要知道哪个节点（或多个节点）发布到该主题。而publisher也不需要知道是否有订阅者或有多少个订阅者。 一个node 可以同时是 subscriber或 publisher ros master node通信模型图 三大通信方式比较表 Topics Services Action Libs 异步 同步 长时间任务 Many-to-many scheme One-to-many Goal-Status-Feedback-Cancel ROS 常见概念图]]></content>
      <categories>
        <category>ros教程</category>
      </categories>
      <tags>
        <tag>ros教程 用ROS学习机器人编程的系统方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS教程-0.1 ROS安装-《用ROS学习机器人编程的系统方法》]]></title>
    <url>%2Fros_tutorial%2F2018-03-21-ROS%E6%95%99%E7%A8%8B-0.1%20ROS%E5%AE%89%E8%A3%85-%E3%80%8A%E7%94%A8ROS%E5%AD%A6%E4%B9%A0%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%BC%96%E7%A8%8B%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B.html</url>
    <content type="text"><![CDATA[Install Linux 14.04.5##选择一种方式安装 linux 易科机器人Ubuntu 14.04.1 for ROS(indigo) by ExBot iso 发行版 安装linux和windows的 双系统 虚拟机Virtualbox Linux 常用命令学习在安装linux之后，你需要知道如何使用linux 常用的linux命令 git 命令 apt-get命令 git 基础(可跳过)常用git命令手册 可参考廖雪峰git教程 也可参考一下视频 了解 github git clone git add &amp; commit git push &amp; pull #安装ROS IndigoROS我推荐Indigo版本，这个版本目前最成熟。 安装教程可参考 ros维基 注：强烈建议使用国内或者新加坡的镜像源，这样能够大大提高安装下载速度。 推荐使用一键 脚本自动安装ROS Indigo。 #配置教程所使用的环境本教程使用教程为：《用ROS学习机器人编程的系统方法》 一键ROS环境配置脚本中的工作空间 设定 恭喜你，完成了ROS环境的配置！ 下面可以跟着教程学习了~]]></content>
      <categories>
        <category>ros教程</category>
      </categories>
      <tags>
        <tag>ros教程 用ROS学习机器人编程的系统方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS教程-1.1 目录-《用ROS学习机器人编程的系统方法》]]></title>
    <url>%2Fros_tutorial%2F2018-03-20-ROS%E6%95%99%E7%A8%8B-0%20%E7%9B%AE%E5%BD%95-%E3%80%8A%E7%94%A8ROS%E5%AD%A6%E4%B9%A0%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%BC%96%E7%A8%8B%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B.html</url>
    <content type="text"><![CDATA[目录 ROS教程-1 ROS安装-《用ROS学习机器人编程的系统方法》 ROS教程-2 ROS安装-《用ROS学习机器人编程的系统方法》 提纲 Network Basics: Nodes, Services, Actions Simulation &amp; Visualization: Gazebo &amp; RVIZ Vision: Cameras, Depth, PCL Manipulation: Control, Motion, Grasping System Integration: Mobile manipulation 书籍推荐 本教程使用的教材：A Systematic Approach to Learning Robot Programming with ROS 其它推荐书籍 ： ROS入门实例、ROS进阶实例 ROS相关学习网站 ROS官网 ROS维基 ROS官方 问答社区 易科机器人实验室 ROS机器人俱乐部 Baxter 创客智造]]></content>
      <categories>
        <category>ros教程</category>
      </categories>
      <tags>
        <tag>ros教程 用ROS学习机器人编程的系统方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git教程]]></title>
    <url>%2Fgit%2F2018-03-17-git_tutorial.html</url>
    <content type="text"><![CDATA[在Windows上安装Git在Windows上使用Git，可以从Git官网直接下载安装程序，（国内镜像），然后按默认选项安装即可。 安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！ 安装完成后，还需要最后一步设置，在命令行输入： 12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot; 第一个版本库repository什么是版本库呢？版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。 所以，创建一个版本库非常简单，首先，选择一个合适的地方，创建一个空目录： 1234$ mkdir learngit$ cd learngit$ pwd/Users/michael/learngit 初始化一个Git仓库通过git init命令把这个目录变成Git可以管理的仓库： 12$ git initInitialized empty Git repository in /Users/michael/learngit/.git/ 把文件添加到版本库git add添加文件1$ git add readme.txt git commit提交1234$ git commit -m &quot;wrote a readme file&quot;[master (root-commit) cb926e7] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt -m 后面输入的是本次提交的说明，可以输入任意内容 工作流程图整个上述过程可以被这张 git 官网上的流程图直观地表现: 图中告诉我们存在4个状态：untracked, unmodified,modified,staged 创建的新文件，且没有git add 则属于untracked状态；add之后为staged状态 staged状态 git commit 之后为 unmodified 状态 当我们修改后，变为modified 状态；需要继续git add 添加，才变为staged状态 当我们git rm之后，变为 untracked状态 记录及修改 (log &amp; diff)在 git 中, 每一次提交(commit)的修改, 都会被单独的保存起来. 也可以说 git 的中的所有文件都是一次次修改累积起来的. 文件好比楼房, 每个 commit 记录 了盖楼需添加或者拿走的材料. 整个施工过程也被记录了下来. 修改记录 log我们来查看版本库的施工过程1$ git log 查看状态statusgit status命令可以让我们时刻掌握仓库当前的状态1$ git status 要随时掌握工作区的状态，使用git status命令。 如果git status告诉你有文件被修改过，用git diff可以查看修改内容。 查看 unstaged如果想要查看这次还没 add (unstaged) 的修改部分 和上个已经 commit 的文件有何不同, 我们将使用 $ git diff: 1$ git diff 查看 staged (–cached)如果你已经 add 了这次修改, 文件变成了 “可提交状态” (staged), 我们可以在 diff 中添加参数 –cached 来查看修改: 12$ git add . # add 全部修改的文件$ git diff --cached 回到从前回到从前 (reset)修改已 commit 的版本有时候我们总会忘了什么, 比如已经提交了 commit 却发现在这个 commit 中忘了附上另一个文件。 接下来我们模拟这种情况.我们最后一个 commit 是 change 2, 我们将要添加另外一个文件, 将这个修改也 commit 进 change 2. 所以我们复制 1.py 这个文件, 改名为 2.py. 并把 2.py 变成 staged, 然后使用 –amend 将这次改变合并到之前的 change 2 中. 123$ git add 2.py$ git commit --amend --no-edit # &quot;--no-edit&quot;: 不编辑, 直接合并到上一个 commit$ git log --oneline # &quot;--oneline&quot;: 每个 commit 内容显示在一行 reset 回到 add 之前有时我们添加 add 了修改, 但是又后悔, 并想补充一些内容再 add. 这时, 我们有一种方式可以回到 add 之前.1234$ git add 1.py$ git status#后悔了 咋办$ git reset 1.py reset 回到 commit 之前在穿梭到过去的 commit 之前, 我们必须了解 git 是如何一步一步累加更改的。 每个 commit 都有自己的 id 数字号, HEAD 是一个指针, 指引当前的状态是在哪个 commit. 最近的一次 commit 在最右边, 我们如果要回到过去, 就是让 HEAD 回到过去并 reset 此时的 HEAD 到过去的位置. 123456789101112131415161718192021222324# 不管我们之前有没有做了一些 add 工作, 这一步让我们回到 上一次的 commit$ git reset --hard HEAD # 输出HEAD is now at 904e1ba change 2-----------------------# 看看所有的log$ git log --oneline# 输出904e1ba change 2c6762a1 change 113be9a7 create 1.py-----------------------# 回到 c10ea64 change 1# 方式1: &quot;HEAD^&quot;$ git reset --hard HEAD^ # 方式2: &quot;commit id&quot;$ git reset --hard c6762a1-----------------------# 看看现在的 log$ git log --oneline# 输出c6762a1 change 113be9a7 create 1.py 怎么 change 2 消失了!!! 还有办法挽救消失的 change 2 吗? 我们可以查看 $ git reflog 里面最近做的所有 HEAD 的改动, 并选择想要挽救的 commit id: 1234567$ git reflog# 输出c6762a1 HEAD@&#123;0&#125;: reset: moving to c6762a1904e1ba HEAD@&#123;1&#125;: commit (amend): change 20107760 HEAD@&#123;2&#125;: commit: change 2c6762a1 HEAD@&#123;3&#125;: commit: change 113be9a7 HEAD@&#123;4&#125;: commit (initial): create 1.py 重复 reset 步骤就能回到 commit (amend): change 2 (id=904e1ba)这一步了: 123456$ git reset --hard 904e1ba$ git log --oneline# 输出904e1ba change 2c6762a1 change 113be9a7 create 1.py 我们又再次奇迹般的回到了 change 2. 回到从前 (checkout 针对单个文件)之前我们使用 reset 的时候是针对整个版本库, 回到版本库的某个过去. 不过如果我们只想回到某个文件的过去, 又该怎么办呢? 改写文件 checkout我们仅仅要对 1.py 进行回到过去操作, 回到 c6762a1 change 1 这一个 commit. 使用 checkout + id c6762a1 + – + 文件目录 1.py, 我们就能将 1.py 的指针 HEAD 放在这个时刻 c6762a1: 1234567$ git log --oneline# 输出904e1ba change 2c6762a1 change 113be9a7 create 1.py---------------------$ git checkout c6762a1 -- 1.py 分支管理分支 (branch)很多时候我们需要给自己或者客户用一个稳定的版本库, 然后同时还在开发另外一个升级版. 自然而然, 我们会想到把这两者分开处理, 用户使用稳定版, 我们开发我们的开发版. 不过 git 的做法却不一样, 它把这两者融合成了一个文件, 使用不同的分支来管理. 分支 图例之前我们说编辑的所有改变都是在一条主分支 master 上进行的. 通常我们会把 master 当作最终的版本, 而开发新版本或者新属性的时候, 在另外一个分支上进行, 这样就能使开发和使用互不干扰了 使用 branch 创建 dev 分支我们之前的文件当中, 仅仅只有一条 master 分支, 我们可以通过 –graph 来观看分支 123456$ git log --oneline --graph# 输出* 47f167e back to change 1 and add comment for 1.py* 904e1ba change 2* c6762a1 change 1* 13be9a7 create 1.py 接着我们建立另一个分支 dev, 并查看所有分支: 123456$ git branch dev # 建立 dev 分支$ git branch # 查看当前分支# 输出 dev * master # * 代表了当前的 HEAD 所在的分支 使用 checkout 切换到 dev 分支当我们想把 HEAD 切换去 dev 分支的时候, 我们可以用到上次说的 checkout: 12345678910$ git checkout dev# 输出Switched to branch &apos;dev&apos;--------------------------$ git branch# 输出* dev # 这时 HEAD 已经被切换至 dev 分支 master 使用 checkout -b + 分支名, 就能直接创建和切换到新建的分支: 12345678910$ git checkout -b dev# 输出Switched to a new branch &apos;dev&apos;--------------------------$ git branch# 输出* dev # 这时 HEAD 已经被切换至 dev 分支 master 在 dev 分支中修改因为当前的指针 HEAD 在 dev 分支上, 所以现在对文件夹中的文件进行修改将不会影响到 master 分支. 我们修改dev分支, 然后再 commit:1$ git commit -am &quot;change 3 in dev&quot; # &quot;-am&quot;: add 所有改变 并直接 commit 假设我们的开发板 dev 已经更新好了, 我们要将 dev 中的修改推送到 master 中, 大家就能使用到正式版中的新功能了. 首先我们要切换到 master, 再将 dev 推送过来.1234567891011$ git checkout master # 切换至 master 才能把其他分支合并过来$ git merge dev # 将 dev merge 到 master 中$ git log --oneline --graph# 输出* f9584f8 change 3 in dev* 47f167e back to change 1 and add comment for 1.py* 904e1ba change 2* c6762a1 change 1* 13be9a7 create 1.py 要注意的是, 如果直接 git merge dev, git 会采用默认的 Fast forward 格式进行 merge, 这样 merge 的这次操作不会有 commit 信息. log 中也不会有分支的图案. 我们可以采取 –no-ff 这种方式保留 merge 的 commit 信息.123456789101112$ git merge --no-ff -m &quot;keep merge info&quot; dev # 保留 merge 信息$ git log --oneline --graph# 输出* c60668f keep merge info|\ | * f9584f8 change 3 in dev # 这里就能看出, 我们建立过一个分支|/ * 47f167e back to change 1 and add comment for 1.py* 904e1ba change 2* c6762a1 change 1* 13be9a7 create 1.py merge 分支冲突情况是这样, 想象不仅有人在做开发版 dev 的更新, 还有人在修改 master 中的一些 bug. 当我们再 merge dev 的时候, 冲突就来了. 因为 git 不知道应该怎么处理 merge 时, 在 master 和 dev 的不同修改. 当创建了一个分支后, 我们同时对两个分支都进行了修改.比如在: master 中的 1.py 加上 # edited in master. dev 中的 1.py 加上 # edited in dev. 当我们想要 merge dev 到 master 的时候: 12345678910$ git branch #查看当前分支 dev* master-------------------------$ git merge dev 合并# 输出Auto-merging 1.pyCONFLICT (content): Merge conflict in 1.pyAutomatic merge failed; fix conflicts and then commit the result. git 发现的我们的 1.py 在 master 和 dev 上的版本是不同的, 所以提示 merge 有冲突. 具体的冲突, git 已经帮我们标记出来, 我们打开 1.py 就能看到:1234567a = 1# I went back to change 1&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD# edited in master=======# edited in dev&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev 所以我们只要在 1.py 中手动合并一下两者的不同就 OK 啦. 然后再 commit 现在的文件, 冲突就解决啦. 1$ git commit -am &quot;solve conflict&quot; 临时修改 (stash)暂存修改假设我们现在在 dev 分支上快乐地改代码:1$ git checkout dev 在 dev 中的 1.py 中加上一行 # feel happy, 然后老板的电话来了, 可是我还没有改进完这些代码. 所以我就用 stash 将这些改变暂时放一边.12345678910111213$ git status -s# 输出 M 1.py------------------$ git stash# 输出Saved working directory and index state WIP on dev: f7d2e3a change 3 in devHEAD is now at f7d2e3a change 3 in dev-------------------$ git status# 输出On branch devnothing to commit, working directory clean # 干净得很 做其它任务然后我们建立另一个 branch 用来完成老板的任务:1234$ git checkout -b boss# 输出Switched to a new branch &apos;boss&apos; # 创建并切换到 boss 然后苦逼地完成着老板的任务, 比如添加 # lovely boss 去 1.py. 然后 commit, 完成老板的任务.123$ git commit -am &quot;job from boss&quot;$ git checkout master$ git merge --no-ff -m &quot;merged boss job&quot; boss 恢复暂存轻松了, 现在可以继续开心的在 dev 上刷代码了.12345$ git checkout dev$ git stash list # 查看在 stash 中的缓存# 输出stash@&#123;0&#125;: WIP on dev: f7d2e3a change 3 in dev 上面说明在 dev 中, 我们的确有 stash 的工作. 现在可以通过 pop 来提取这个并继续工作了.12345678910111213141516$ git stash pop# 输出On branch devChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: 1.pyno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)Dropped refs/stash@&#123;0&#125; (23332b7edc105a579b09b127336240a45756a91c)----------------------$ git status -s# 输出 M 1.py # 和最开始一样了]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git忽略规则及.gitignore规则正确姿势]]></title>
    <url>%2Fgit%2F2018-03-16-gitignore.html</url>
    <content type="text"><![CDATA[实现需求在git中如果想忽略掉某个文件或者文件夹，不想这个文件或者文件夹提交到版本库中，可以使用修改根目录中 .gitignore 文件的方法（如无，则需自己手工建立此文件）。这个文件每一行保存了一个匹配的规则例如： 创建gitignore文件1touch .gitignore 注释Git忽略规则1234567# 此为注释 – 将被 Git 忽略*.a # 忽略所有 .a 结尾的文件!lib.a # 但 lib.a 除外/-songaporesite # 仅仅忽略项目根目录下的 songaporesite 文件，不包括 subdir/songaporesitesongapore/ # 忽略 songapore文件夹/ 目录下的所有文件以及文件夹本身doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt gitignore忽略规则不生效原因规则很简单，不做过多解释，但是有时候在项目开发过程中，突然心血来潮想把某些目录或文件加入忽略规则，按照上述方法定义后发现并未生效，原因是.gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。那么解决方法就是先把本地缓存删除（改变成未track状态），然后再提交： 123git rm -r --cached .git add .git commit -m &apos;update .gitignore&apos;]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub当作私密的版本控制系统远端版本库私有化哈]]></title>
    <url>%2Fgit%2F2018-03-15-githubyaunchengjiami.html</url>
    <content type="text"><![CDATA[目的我打算把所有服务器的配置文件用git管理起来，这样可以记录配置变更状况。 但是有一个问题是，如何多人协作？服务器配置信息非常敏感，如果这个版本库泄漏，整个公司的服务器架构就彻底泄漏了。 这个版本库只能在开发者本地电脑里面解密，远程托管版本库的服务器不应该知道文件里面的内容。 那么解决办法就是：本地git版本库是解密的，在上传过程中内容全部加密，密钥保存在本地，同时密钥可以分享给其他开发者。 考虑了几个解决方案： git-crypt：可以加密部分文件，原理是加上了加密的fiter和diff， 但是官方说只适合加密部分文件，而不适合全版本库加密。部分文件加密很容易造成信息泄漏，一定要全版本库加密才适合。 串联sshfs和远程服务器加密文件系统encfs：首先用sshfs加载远端文件系统，然后用encfs创建加密文件系统。 我估计无法解决多人同时push情况下的竞争条件，并且encfs有安全漏洞，使用上push/pull之前需要加载两层文件系统，不是很方便。 git-remote-gcrypt用gpg进行远端加密。 比较符合我预期的模式，但是用gpg不是特别方便协作。但是别的方法走不通，只有这个方法可用。 使用方法安装git-remote-gcrypt和gnupg1sudo apt-get install git-remote-gcrypt gnupg 创建一个gpg的key， 需要设置用户名，邮箱，描述等，不要设置过期时间1gpg --gen-key 记录一下生成的key的ID，比如2048R/songapore013里面的songapore013，2048代表加密轮数，越多越不容易破解1gpg --list-keys 生成一个测试版本库1234mkdir test1 &amp;&amp; cd test1git init .echo &quot;test&quot; &gt; a.txtgit add . &amp;&amp; git ci -m &quot;update&quot; 创建一个测试project在你的github上面创建一个project，比如：https://github.com/songapore 配置远端加密版本库1git remote add cryptremote gcrypt::git@github.com:songapore/songapore.git 最好指定用哪个key加密 这样可以共享这个key给其他人用1git config remote.cryptremote.gcrypt-participants &quot;songapore013&quot; push到远端1git push cryptremote master 访问远端版本库，看看文件内容，和commit里面的信息，是不是都是加密的？ 如何分享给其他人导出key1gpg --export-secret-key -a &quot;share@share.com&quot; &gt; secretkey.asc 把secretkey.asc分享给其他人，拷贝的时候记得先压缩加密一下再发送，更安全 别人电脑里面导入1gpg --import secretkey.asc 下载代码12git clone gcrypt::git@github.com:songapore/songapore.git test2 // test2是git clone 在本地的文件名 也要指定一下用什么key加密1git config remote.cryptremote.gcrypt-participants &quot;songapore013&quot; 用这种方法，可以用git管理一些私密又需要协作的信息（比如服务器配置）， 也可以把github当作私密的版本控制系统来用（commit的消息还是明文的）。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git github</tag>
      </tags>
  </entry>
</search>
